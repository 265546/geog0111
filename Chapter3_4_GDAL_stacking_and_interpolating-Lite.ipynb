{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Stacking and interpolating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#3.4-Stacking-and-interpolating-data\" data-toc-modified-id=\"3.4-Stacking-and-interpolating-data-1\">3.4 Stacking and interpolating data</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.4.1-Introduction\" data-toc-modified-id=\"3.4.1-Introduction-1.1\">3.4.1 Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.4.1.1-Test-your-login\" data-toc-modified-id=\"3.4.1.1-Test-your-login-1.1.1\">3.4.1.1 Test your login</a></span></li></ul></li><li><span><a href=\"#3.4.2-QA-data\" data-toc-modified-id=\"3.4.2-QA-data-1.2\">3.4.2 QA data</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.4.2.1-Why-QA-data?\" data-toc-modified-id=\"3.4.2.1-Why-QA-data?-1.2.1\">3.4.2.1 Why QA data?</a></span></li><li><span><a href=\"#3.4.2.2-Deriving-a-weight-from-QA\" data-toc-modified-id=\"3.4.2.2-Deriving-a-weight-from-QA-1.2.2\">3.4.2.2 Deriving a weight from QA</a></span></li><li><span><a href=\"#3.4.2.3-Extracting-relevant-bit-fields\" data-toc-modified-id=\"3.4.2.3-Extracting-relevant-bit-fields-1.2.3\">3.4.2.3 Extracting relevant bit fields</a></span></li></ul></li><li><span><a href=\"#3.4.2-A-time-series\" data-toc-modified-id=\"3.4.2-A-time-series-1.3\">3.4.2 A time series</a></span></li><li><span><a href=\"#Weighted-interepolation\" data-toc-modified-id=\"Weighted-interepolation-1.4\">Weighted interepolation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Smoothing\" data-toc-modified-id=\"Smoothing-1.4.1\">Smoothing</a></span></li><li><span><a href=\"#weighted-smoothing\" data-toc-modified-id=\"weighted-smoothing-1.4.2\">weighted smoothing</a></span></li></ul></li><li><span><a href=\"#Making-movies\" data-toc-modified-id=\"Making-movies-1.5\">Making movies</a></span><ul class=\"toc-item\"><li><span><a href=\"#Javascript-HTML\" data-toc-modified-id=\"Javascript-HTML-1.5.1\">Javascript HTML</a></span></li><li><span><a href=\"#Animated-gif\" data-toc-modified-id=\"Animated-gif-1.5.2\">Animated gif</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[up to 3.0](Chapter3_1_GDAL.ipynb)]\n",
    "\n",
    "\n",
    "## 3.4.1 Introduction\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "* develop code to produce a stacked dataset of spatio-temporal data on a grid\n",
    "* interpolate over any missing data\n",
    "* smooth the dataset\n",
    "\n",
    "### 3.4.1.1 Test your login\n",
    "\n",
    "Let's first test your NASA login:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login error ... \n",
      "try entering your username password again\n",
      "then re-run this cell until it works\n"
     ]
    }
   ],
   "source": [
    "import geog0111.nasa_requests as nasa_requests\n",
    "from geog0111.cylog import cylog\n",
    "\n",
    "url = 'https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2018.09.30/' \n",
    "        \n",
    "# grab the HTML information\n",
    "try:\n",
    "    html = nasa_requests.get(url).text\n",
    "    # test a few lines of the html\n",
    "    if html[:20] == '<!DOCTYPE HTML PUBLI':\n",
    "        print('this seems to be ok ... ')\n",
    "        print('use cylog().login() anywhere you need to specify the tuple (username,password)')\n",
    "except:\n",
    "    print('login error ... ')\n",
    "    print('try entering your username password again')\n",
    "    print('then re-run this cell until it works')\n",
    "    print('If its wednesday, ignore this!')\n",
    "    # uncomment next line to reset password\n",
    "    #cylog(init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2016\n",
      " ****\n",
      "MCD15A3H.A2016001.h17v03.006.2016007075833.hdf\n",
      "MCD15A3H.A2016001.h17v04.006.2016007074809.hdf\n",
      "MCD15A3H.A2016001.h18v03.006.2016007073724.hdf\n",
      "MCD15A3H.A2016001.h18v04.006.2016007073726.hdf\n",
      "MCD15A3H.A2016005.h17v03.006.2016013012017.hdf\n",
      "MCD15A3H.A2016005.h17v04.006.2016013011406.hdf\n",
      "MCD15A3H.A2016005.h18v03.006.2016013012348.hdf\n",
      "MCD15A3H.A2016005.h18v04.006.2016013012025.hdf\n",
      "\n",
      " 2017\n",
      " ****\n",
      "MCD15A3H.A2017001.h17v03.006.2017014005341.hdf\n",
      "MCD15A3H.A2017001.h17v04.006.2017014005344.hdf\n",
      "MCD15A3H.A2017001.h18v03.006.2017014005401.hdf\n",
      "MCD15A3H.A2017001.h18v04.006.2017014005359.hdf\n",
      "MCD15A3H.A2017005.h17v03.006.2017017141758.hdf\n",
      "MCD15A3H.A2017005.h17v04.006.2017017141805.hdf\n",
      "MCD15A3H.A2017005.h18v03.006.2017017141813.hdf\n",
      "MCD15A3H.A2017005.h18v04.006.2017017141824.hdf\n"
     ]
    }
   ],
   "source": [
    "from geog0111.geog_data import *\n",
    "\n",
    "destination_folder = Path('data')\n",
    "if not destination_folder.exists():\n",
    "        dest_path.mkdir()\n",
    "\n",
    "# we have the filenames provided \n",
    "# in data/lai_filelist_2016.dat.txt\n",
    "for year in [2016,2017]:\n",
    "    control_file = f'data/lai_filelist_{year}.dat.txt'\n",
    "    # read the ascii data from the file in\n",
    "    filenames = open(control_file).read().split()\n",
    "\n",
    "    # get the local files\n",
    "    # set verbose=True if you want to see what is happening\n",
    "    done = [procure_dataset(f,\\\n",
    "                verbose=False,\\\n",
    "                destination_folder=destination_folder) \n",
    "                                    for f in filenames]\n",
    "    # done should be all True if this has worked\n",
    "\n",
    "    # print the first 8 in the list, just to see it looks ok\n",
    "    print(f'\\n {year}\\n','*'*len(str(year)))\n",
    "    for f in filenames[:8]:\n",
    "        print (f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make sure you have the world borders ESRI shape file you need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil \n",
    "from pathlib import Path\n",
    "\n",
    "# zip file\n",
    "zipfile = 'TM_WORLD_BORDERS-0.3.zip'\n",
    "# URL\n",
    "tm_borders_url = f\"http://thematicmapping.org/downloads/{zipfile}\"\n",
    "# destibnation folder\n",
    "destination_folder = Path('data')\n",
    "\n",
    "# set up some filenames\n",
    "zip_file = destination_folder.joinpath(zipfile)\n",
    "shape_file = zip_file.with_name(zipfile.replace('zip','shp'))\n",
    "\n",
    "# download zip if need to\n",
    "if not Path(zip_file).exists():\n",
    "    r = requests.get(tm_borders_url)\n",
    "    with open(zip_file, 'wb') as fp:\n",
    "        fp.write (r.content)\n",
    "\n",
    "# extract shp from zip if need to\n",
    "if not Path(shape_file).exists():\n",
    "    shutil.unpack_archive(zip_file.as_posix(),\n",
    "                         extract_dir=destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.2 QA data\n",
    "\n",
    "\n",
    "### 3.4.2.1 Why QA data?\n",
    "\n",
    "The quality of data varies according to sampling and other factors. For satellite-derived data using optical wavelengths, the two main controls are orbital constraints and cloud cover. We generally define a 'quaity' data layer to express this.\n",
    "\n",
    "To use a satellite-derived dataset, we need to look at 'quality' data for dataset (and/or uncertainty).\n",
    "\n",
    "For example, if interpolating data, we would want to base the weight we put on any sample on the 'quality' of that sample. This will be expressed by either some QC (Quality Control) assessment ('good', 'ok', 'bad') or some measure of uncertainty (or both).\n",
    "\n",
    "Here, we will use the QA information in the LAI product to generate a sample weighting scheme. We shall later use this weighting for data smoothing and interpolation.\n",
    "\n",
    "First, let's access the LAI and QA datasets.\n",
    "\n",
    "We can do this by specifying either `Lai_500m` or `FparLai_QC` in the dataset label.\n",
    "\n",
    "Let's set up the variables we will use, including a pattern to match the `tile` information we need.\n",
    "\n",
    "Here, we have:\n",
    "\n",
    "    tile = 'h1[7-8]v0[3-4]'\n",
    "    \n",
    "which we can interpret as:\n",
    "\n",
    "    h17v03, h17v04, h18v03, or h18v04\n",
    "    \n",
    "The tile definition ius useful for us to use in any output names (so we can identify it from the name). But the string `h1[7-8]v0[3-4]` contains some 'awkward' characters, namely `[`, `]` and `-` that we might prefer not to use in a filename.\n",
    "\n",
    "So we derive a new descriptor that we call `tile_` which is more 'filename friendly'.\n",
    "\n",
    "Thye rest of the code below proceeds much the same as code we have previously used.\n",
    "\n",
    "We build a gdal VRT file from the set of hdf files using `gdal.BuildVRT()`.\n",
    "\n",
    "Then we crop to the vector defined by the `FIPS` variable in the shapefile (the country code here) using `gdal.Warp()`. We save this as a gdal VRT file, decsribed by the variable `clipped_file`.\n",
    "\n",
    "When we make gdal calls, we need to force the system to write files to disc. This can be done by closing the (effective) file descriptors, or by deleting the variable `g` in this case. If you don't do that, you can hit file synchronisation problems. You should always close (or delete) file descriptors when you have finished with them.\n",
    "\n",
    "You should be able to follow what goes on in the code block below. We will re-use these same ideas later, so it is worthwhile understanding the steps we go through now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipfile data/MCD15A3H.A2017149.h1_78_v0_34_LU.006\n",
      "opfile data/MCD15A3H.A2017h1_78_v0_34_LU.006\n",
      "['data/MCD15A3H.A2017h1_78_v0_34_LU.006.149_clip.Lai_500m.vrt', 'data/MCD15A3H.A2017h1_78_v0_34_LU.006.149_clip.FparLai_QC.vrt']\n"
     ]
    }
   ],
   "source": [
    "import gdal\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from geog0111.create_blank_file import create_blank_file\n",
    "from datetime import datetime\n",
    "\n",
    "#-----------------\n",
    "# set up the dataset information\n",
    "destination_folder = Path('data')\n",
    "year = 2017\n",
    "product = 'MCD15A3H'\n",
    "version = 6\n",
    "tile = 'h1[7-8]v0[3-4]'\n",
    "doy = 149\n",
    "params =  ['Lai_500m', 'FparLai_QC']\n",
    "# Luxembourg\n",
    "FIPS = \"LU\"\n",
    "#-----------------\n",
    "\n",
    "# make a text-friendly version of tile\n",
    "tile_ = tile.replace('[','_').replace(']','_').replace('-','')+FIPS\n",
    "\n",
    "# location of the shapefile\n",
    "shape_file = destination_folder.\\\n",
    "                 joinpath('TM_WORLD_BORDERS-0.3.shp').as_posix()\n",
    "\n",
    "# define strings for the ip and op files\n",
    "ipfile = destination_folder.\\\n",
    "                joinpath(f'{product}.A{year}{doy:03d}.{tile_}.{version:03d}').as_posix()\n",
    "\n",
    "opfile = ipfile.replace(f'{doy:03d}.','').replace(tile,tile_)\n",
    "\n",
    "print('ipfile',ipfile)\n",
    "print('opfile',opfile)\n",
    "\n",
    "# now glob the hdf files matching the pattern\n",
    "filenames = list(destination_folder\\\n",
    "                .glob(f'{product}.A{year}{doy:03d}.{tile}.{version:03d}.*.hdf'))\n",
    "\n",
    "# start with an empty list\n",
    "ofiles = []\n",
    "\n",
    "# loop over each parameter we need\n",
    "for d in params:\n",
    "    \n",
    "    # mangle the dataset names\n",
    "    dataset_names = sorted([f'HDF4_EOS:EOS_GRID:'+\\\n",
    "                         f'\"{file_name.as_posix()}\":'+\\\n",
    "                         f'MOD_Grid_MCD15A3H:{d}'\\\n",
    "                            for file_name in filenames])\n",
    "\n",
    "    # derive some filenames for vrt files\n",
    "    spatial_file = f'{opfile}.{doy:03d}.{d}.vrt'\n",
    "    clipped_file = f'{opfile}.{doy:03d}_clip.{d}.vrt'\n",
    "    \n",
    "    # build the files\n",
    "    g = gdal.BuildVRT(spatial_file, dataset_names)\n",
    "    if(g):\n",
    "        del(g)\n",
    "        g = gdal.Warp(clipped_file,\\\n",
    "                                   spatial_file,\\\n",
    "                                   format='VRT', dstNodata=255,\\\n",
    "                                   cutlineDSName=shape_file,\\\n",
    "                                   cutlineWhere=f\"FIPS='{FIPS}'\",\\\n",
    "                                   cropToCutline=True)\n",
    "        if (g):\n",
    "            del(g)\n",
    "        ofiles.append(clipped_file)\n",
    "print(ofiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.4.1**\n",
    "\n",
    "* examine the code block above, and write a function that takes as inputs the variables given in the block enclosed by `#-----------------`, the dataset information\n",
    "* the code should setup the VRT files and return the list of clipped dataset filenames: `['data/MCD15A3H.A2017h1_78_v0_34_LU.006.149_clip.Lai_500m.vrt', 'data/MCD15A3H.A2017h1_78_v0_34_LU.006.149_clip.FparLai_QC.vrt']` here.\n",
    "* Make sure you test your function: check that it generates the files you expect from the inputs you give.\n",
    "* try to develop an automated test to see that it has worked (Homework)\n",
    "\n",
    "**Hint**\n",
    "\n",
    "Be clear about what you are doing in your code.\n",
    "\n",
    "The purpose of this function is to build clipped VRT files for the conditions you set.\n",
    "\n",
    "The conditions are the parameters driving the function.\n",
    "\n",
    "The list of files you develop are returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do exercise here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2.2 Deriving a weight from QA\n",
    "\n",
    "We now have some example files describing the LAI and QC datasets:\n",
    "\n",
    "    data/MCD15A3H.A2017h1_78_v0_34_LU.006.149_clip.Lai_500m.vrt\n",
    "    data/MCD15A3H.A2017h1_78_v0_34_LU.006.149_clip.FparLai_QC.vrt\n",
    "    \n",
    "What we want to develop here is a translation from the QA information (given in `FparLai_QC`) to a *weight* that we can apply to the data. \n",
    "\n",
    "If the quality is poor, we want a low weight. If the quality is good, a high weight. It makes sense to call the highest weight 1.0.\n",
    "\n",
    "The LAI dataset is decribed [on the NASA page](https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/mcd15a3h_v006), with the bit field information given in the [file spec](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MCD15A3H)\n",
    "\n",
    "         BITFIELDS\n",
    "       -------------\n",
    "        0,0  MODLAND_QC bits\n",
    "             '0' =  Good Quality (main algorithm with or without saturation)\n",
    "             '1' =  Other Quality (back-up algorithm or fill values)\n",
    "\n",
    "        1,1 SENSOR\n",
    "             '0' = Terra\n",
    "             '1' = Aqua\n",
    "\n",
    "        2,2  DEADDETECTOR\n",
    "             '0' = Detectors apparently fine for up to 50% of channels 1,2\n",
    "             '1' = Dead detectors caused >50% adjacent detector retrieval\n",
    "\n",
    "        3,4  CLOUDSTATE (this inherited from Aggregate_QC bits {0,1} cloud state)\n",
    "             '00' = 0 Significant clouds NOT present (clear)\n",
    "             '01' = 1 Significant clouds WERE present\n",
    "             '10' = 2 Mixed cloud present on pixel\n",
    "             '11' = 3 Cloud state not defined,assumed clear\n",
    "\n",
    "        5,7  SCF_QC (3-bit, (range '000'..100') 5 level Confidence Quality score.\n",
    "             '000' = 0, Main (RT) method used, best result possible (no saturation)\n",
    "             '001' = 1, Main (RT) method used with saturation. Good,very usable\n",
    "             '010' = 2, Main (RT) method failed due to bad geometry, empirical algorithm used\n",
    "             '011' = 3, Main (RT) method failed due to problems other than geometry, \n",
    "                                  empirical algorithm used\n",
    "             '100' = 4, Pixel not produced at all, value coudn't be retrieved \n",
    "                        (possible reasons: bad L1B data, unusable MOD09GA data)\n",
    "\n",
    "For LAI, we can use the QA information contained in bits 5-7 of `FparLai_QC` to achieve this. \n",
    "\n",
    "The valid codes for `SCF_QC` here are:\n",
    "\n",
    "    0 : Main (RT) method used best result possible (no saturation)\n",
    "    1 : Main (RT) method used with saturation. Good very usable\n",
    "    2 : Main (RT) method failed due to bad geometry empirical algorithm used\n",
    "    3 : Main (RT) method failed due to problems other than geometry empirical algorithm used\n",
    "    \n",
    "    \n",
    "where we have translated the binary representations above to decimal.\n",
    "\n",
    "A useful way of this to some weight is to define a real number $n$, where $0 <= n < 1$ and raise this to the power of `SCF_QC`.\n",
    "\n",
    "So, for example is we set `n = 0.61803398875` (the [inverse golden ratio](https://en.wikipedia.org/wiki/Golden_ratio)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCF_QC: 0 => weight 1.0000\n",
      "SCF_QC: 1 => weight 0.6180\n",
      "SCF_QC: 2 => weight 0.3820\n",
      "SCF_QC: 3 => weight 0.2361\n"
     ]
    }
   ],
   "source": [
    "n = 0.61803398875\n",
    "\n",
    "for SCF_QC in [0,1,2,3]:\n",
    "    weight = n**SCF_QC\n",
    "    print(f'SCF_QC: {SCF_QC} => weight {weight:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have the following meaning for the weights:\n",
    "\n",
    "\n",
    "    1.0000 : Main (RT) method used best result possible (no saturation)\n",
    "    0.6180 : Main (RT) method used with saturation. Good very usable\n",
    "    0.3820 : Main (RT) method failed due to bad geometry empirical algorithm used\n",
    "    0.2361 : Main (RT) method failed due to problems other than geometry empirical algorithm used\n",
    "    \n",
    "  \n",
    "Altghough we could vary the value of $n$ used and get subtle variations, this sort of weighting should produce the desired result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.4.2**\n",
    "\n",
    "* write a function that converts from `SCF_QC` value to weight. \n",
    "* Use the given value of $n$ as default, by let it be changed using a keyword.\n",
    "* make sure any value outside the integer range 0 to 3 inclusive returns a weight of 0.0\n",
    "* try to make your function operate on arrays.\n",
    "* show some tests of your function.\n",
    "\n",
    "**Hint**\n",
    "\n",
    "Since only `[0,1,2,3]` are valid inputs, you could use conditions such as:\n",
    "\n",
    "    (SCF_QC == i) * (n ** i)\n",
    "\n",
    "for valid values of `i`. This should then work correctly for arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do exercise here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2.3 Extracting relevant bit fields\n",
    "\n",
    "We still have the task of getting `SFC_QC` by extracting bits 5-7 from the QA dataset.\n",
    "\n",
    "Let's be clear what we mean by this.\n",
    "\n",
    "The dataset `FparLai_QC` is of data type `uint8`, unsigned 8-bit integer (i.e. unsigned byte). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "2^8 = 256\n"
     ]
    }
   ],
   "source": [
    "import gdal\n",
    "\n",
    "# read our example data in\n",
    "ofiles = ['data/MCD15A3H.A2017h1_78_v0_34_LU.006.149_clip.Lai_500m.vrt', \\\n",
    "          'data/MCD15A3H.A2017h1_78_v0_34_LU.006.149_clip.FparLai_QC.vrt']\n",
    "params = ['Lai_500m', 'FparLai_QC']\n",
    "lai = [gdal.Open(ofiles[i]).ReadAsArray() for i in range(len(params))]\n",
    "\n",
    "FparLai_QC = lai[1]\n",
    "\n",
    "# print some information\n",
    "print(FparLai_QC.dtype)\n",
    "print('2^8 =',2**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all 8 bits are set to 1, it is equal to 255 in decimal. \n",
    "\n",
    "In Python, we can write a number in binary (base 2) repersentation by starting it with `0b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "x = 0b11111111\n",
    "\n",
    "print(int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because the bits `11111111` are interpreted as:\n",
    "\n",
    "    1 x 2^0 +\n",
    "    1 x 2^1 +\n",
    "    1 x 2^2 +\n",
    "    1 x 2^3 +\n",
    "    1 x 2^4 +\n",
    "    1 x 2^5 +\n",
    "    1 x 2^6 +\n",
    "    1 x 2^7 \n",
    "    \n",
    "reading the bit fields from back to front.\n",
    "\n",
    "This is the same as:\n",
    "\n",
    "    1 x 1 +\n",
    "    1 x 2 +\n",
    "    1 x 4 +\n",
    "    1 x 8 + \n",
    "    1 x 16 +\n",
    "    1 x 32 +\n",
    "    1 x 64 +\n",
    "    1 X 128 = 255\n",
    "    \n",
    "Taking an example of a shorted bit field, how then do we interpret `0b1011`?\n",
    "\n",
    "This is:\n",
    "\n",
    "    1 x 2^0 +\n",
    "    1 x 2^1 +\n",
    "    0 x 2^2 +\n",
    "    1 x 2^3 \n",
    "    \n",
    "(reading back to front), so:\n",
    "\n",
    "    1 x 1 +\n",
    "    1 x 2 +\n",
    "    0 x 4 +\n",
    "    1 x 8 = 11 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "x = 0b1011\n",
    "\n",
    "print(int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain bit shift and bitwise and mask &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "ofiles = ['data/MCD15A3H.A2017h1_78_v0_34_LU.006.149_clip.Lai_500m.vrt', \\\n",
    "          'data/MCD15A3H.A2017h1_78_v0_34_LU.006.149_clip.FparLai_QC.vrt']\n",
    "params = ['Lai_500m', 'FparLai_QC']\n",
    "lai = [gdal.Open(ofiles[i]).ReadAsArray() for i in range(len(params))]\n",
    "\n",
    "\n",
    "lai[0] = lai[0] * 0.1\n",
    "# if we want bit field 5-7\n",
    "# we form a binary mask\n",
    "mask57 = 0b11100000\n",
    "# and right shift 5 (>> 5)\n",
    "lai[1] = (lai[1] & mask57) >> 5\n",
    "# 0 to 3 are good\n",
    "scale = 0.61803398875\n",
    "lai[1] = (scale**0) * (lai[1] == 0).astype(float) + \\\n",
    "         (scale**1) * (lai[1] == 1).astype(float) + \\\n",
    "         (scale**2) * (lai[1] == 2).astype(float) + \\\n",
    "         (scale**3) * (lai[1] == 3).astype(float)\n",
    "    \n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True,\n",
    "                       figsize=(10,5))\n",
    "axs = np.array(axs).T.flatten()\n",
    "\n",
    "for i in range(len(params)):\n",
    "    img = axs[i].imshow(lai[i], interpolation=\"nearest\",\n",
    "                 cmap=plt.cm.inferno_r)\n",
    "    axs[i].set_title(params[i])\n",
    "    plt.colorbar(img,ax=axs[i],shrink=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.2 A time series\n",
    "\n",
    "You should now know how to access and download datasets from the NASA servers and have developed functions to do this.\n",
    "\n",
    "You should also know how to select a dataset from a set of hdf files, and mosaic, mask and crop the data to correspond to some vector boundary. This is a very common task in geospatial processing.\n",
    "\n",
    "We now consider the case where we want to analyse a time series of data. We will use LAI over time to exemplify this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/MCD15A3H.A2017.h1_78_v0_34_LU.006.Lai_500m.vrt\n",
      "data/MCD15A3H.A2017.h1_78_v0_34_LU.006.FparLai_QC.vrt\n"
     ]
    }
   ],
   "source": [
    "import gdal\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from geog0111.create_blank_file import create_blank_file\n",
    "from datetime import datetime\n",
    "\n",
    "destination_folder = Path('data')\n",
    "year = 2017\n",
    "product = 'MCD15A3H'\n",
    "version = 6\n",
    "tile = 'h1[7-8]v0[3-4]'\n",
    "params =  ['Lai_500m', 'FparLai_QC']\n",
    "# time step\n",
    "dt = 4\n",
    "\n",
    "\n",
    "tile_ = tile.replace('[','_').replace(']','_').replace('-','')+FIPS\n",
    "\n",
    "shape_file = destination_folder.\\\n",
    "                 joinpath('TM_WORLD_BORDERS-0.3.shp').as_posix()\n",
    "\n",
    "allopfile = destination_folder.\\\n",
    "                joinpath(f'{product}.A{year}.{tile_}.{version:03d}')\n",
    "\n",
    "ndays_in_year = (datetime(year,12,31) - datetime(year,1,1)).days + 1\n",
    "\n",
    "\n",
    "for d in params:\n",
    "    old_clip = None\n",
    "    allvrt = []\n",
    "    bandNames = []\n",
    "    for doy in range(1,ndays_in_year+1,dt):\n",
    "\n",
    "        ipfile = destination_folder.\\\n",
    "                    joinpath(f'{product}.A{year}{doy:03d}.{tile_}.{version:03d}').as_posix()\n",
    "\n",
    "        opfile = ipfile.replace(f'{doy:03d}.','').replace(tile,tile_)\n",
    "\n",
    "        filenames = destination_folder\\\n",
    "                    .glob(f'{product}.A{year}{doy:03d}.{tile}.{version:03d}.*.hdf')\n",
    "\n",
    "        dataset_names = sorted([f'HDF4_EOS:EOS_GRID:'+\\\n",
    "                             f'\"{file_name.as_posix()}\":'+\\\n",
    "                             f'MOD_Grid_MCD15A3H:{d}'\\\n",
    "                                for file_name in filenames])\n",
    "        spatial_file = f'{opfile}.{doy:03d}.{d}.vrt'\n",
    "        clipped_file = f'{opfile}.{doy:03d}_clip.{d}.vrt'\n",
    "        if len(dataset_names):\n",
    "            g = gdal.BuildVRT(spatial_file, dataset_names)\n",
    "            if(g):\n",
    "                del(g)\n",
    "                g = gdal.Warp(clipped_file,\\\n",
    "                                   spatial_file,\\\n",
    "                                   format='VRT', dstNodata=255,\\\n",
    "                                   cutlineDSName=shape_file,\\\n",
    "                                   cutlineWhere=f\"FIPS='{FIPS}'\",\\\n",
    "                                   cropToCutline=True)\n",
    "        elif old_clip:\n",
    "            blank_file_tiff = f'{opfile}_blank.tiff'\n",
    "            # generate a blank dataset in case of missing days\n",
    "            if not Path(blank_file_tiff).exists():\n",
    "                # copy info\n",
    "                create_blank_file(old_clip,blank_file_tiff,value=255)\n",
    "\n",
    "            # build a vrt\n",
    "            g = gdal.BuildVRT(clipped_file, [blank_file_tiff])\n",
    "\n",
    "        if (g):\n",
    "            del(g)\n",
    "            bandNames.append(f'DOY {doy:03d}')\n",
    "            allvrt.append(clipped_file)\n",
    "\n",
    "        old_clip = clipped_file\n",
    "\n",
    "\n",
    "\n",
    "    g = gdal.BuildVRT(f'{allopfile.as_posix()}.{d}.vrt', allvrt,\\\n",
    "                      options=gdal.BuildVRTOptions(VRTNodata=255,\\\n",
    "                                                   srcNodata=255,\\\n",
    "                                                   allowProjectionDifference=True,\\\n",
    "                                                   separate=True))\n",
    "    if (g):\n",
    "        # set band names\n",
    "        for i in range(g.RasterCount):\n",
    "            g.GetRasterBand(i+1).SetDescription(bandNames[i])\n",
    "\n",
    "        # close and flush file\n",
    "        del g\n",
    "        print (f'{allopfile.as_posix()}.{d}.vrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 176, 123)\n"
     ]
    }
   ],
   "source": [
    "import gdal\n",
    "import numpy as np\n",
    "\n",
    "destination_folder = Path('data')\n",
    "year = 2017\n",
    "product = 'MCD15A3H'\n",
    "version = 6\n",
    "tile = 'h1[7-8]v0[3-4]'\n",
    "params =  ['Lai_500m', 'FparLai_QC']\n",
    "FIPS = 'LU'\n",
    "\n",
    "tile_ = tile.replace('[','_').replace(']','_').replace('-','')+FIPS\n",
    "allopfile = destination_folder.\\\n",
    "                joinpath(f'{product}.A{year}.{tile_}.{version:03d}')\n",
    "\n",
    "\n",
    "lai = []\n",
    "for d in params:\n",
    "    \n",
    "    g = gdal.Open(f'{allopfile.as_posix()}.{d}.vrt',gdal.GA_ReadOnly)\n",
    "    data = np.array([g.GetRasterBand(b+1).ReadAsArray() \\\n",
    "                for b in range(g.RasterCount)])\n",
    "\n",
    "    lai.append(data)\n",
    "\n",
    "lai[0] = lai[0] * 0.1\n",
    "# if we want bit field 5-7\n",
    "# we form a binary mask\n",
    "mask57 = 0b11100000\n",
    "# and right shift 5 (>> 5)\n",
    "lai[1] = (lai[1] & mask57) >> 5\n",
    "# 0 to 3 are good\n",
    "scale = 0.61803398875\n",
    "lai[1] = (scale**0) * (lai[1] == 0).astype(float) + \\\n",
    "         (scale**1) * (lai[1] == 1).astype(float) + \\\n",
    "         (scale**2) * (lai[1] == 2).astype(float) + \\\n",
    "         (scale**3) * (lai[1] == 3).astype(float)\n",
    "    \n",
    "print(lai[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted interepolation\n",
    "\n",
    "### Smoothing\n",
    "\n",
    "There are many approaches to weighted interpolation. One such is to use a convolution smoothing operation.\n",
    "\n",
    "In convolution, we combine a *signal* $y$ with a *filter* $f$ to achieve a filtered signal. For example, if we have an noisy signal, we will attempt to reduce the influence of high frequency information in the signal (a 'low pass' filter, as we let the low frequency information *pass*).\n",
    "\n",
    "In this approach, we define a digital filter (convolution filter) that should be some sort of weighted average function. A typical filter is the Gaussian, defined by the parameter $\\sigma$. The larger the value of $\\sigma$, the 'wider' the filter, which means that the weighted average will be takjen over a greater extent.\n",
    "\n",
    "We do not expect you to be overly concerned with the code in these sections below, as the main effort should be directed at understanding smoothing and interpolation at this point.\n",
    "\n",
    "Let's look at this filter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A digital (discrete) convolution uses a sampled signal and filter (represented on a grid).\n",
    "\n",
    "Without going into the maths, the convolution operates by running the filter centred on $x_c$ over the extent of the signal as illustrated below.\n",
    "\n",
    "*At each value of $x_c$*, the filter is **multiplied by the signal**. Clearly, where the filter is zero, the influence of the signal is zero. So, the filter effectively selects a local window of data points (shown as green crosses below). The result, i.e. the filtered signal, is simply the weighted average of these local samples. This can be seen in the lower panel, where the green dot shows the filtered signal at $x_c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolution of a low pass ('smoothing') filter with a signal results in a smoothing of the signal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The degree of smoothing is greater, the larger the value of $\\sigma$ (i.e. the broader the convolution filter). Eventually, the signal would go 'flat', i.e. be a constant (weighted mean) value, if we used a very broad filter.\n",
    "\n",
    "For small values of $\\sigma$ though, the signal is still rather noisy. \n",
    "\n",
    "There is a trade-off then between noise suppression and the degree of generalisation.\n",
    "\n",
    "We could define some concept of an 'optimium' value of $\\sigma$, for example using [cross validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)). But often we can decide empirically an appropriate filter width.\n",
    "\n",
    "We perform the convolution using:\n",
    "\n",
    "    convolve1d(y, filter,mode='wrap')\n",
    "    \n",
    "from the `scipy.ndimage.filters` library.\n",
    "\n",
    "The first argument is the signal to be filtered. The second is the filter (the Gaussian here). \n",
    "\n",
    "We set \n",
    "\n",
    "    mode='wrap'\n",
    "    \n",
    "which defines the boundary conditions to be periodic ('wrapped around'). This would generally be appropriate for time series e.g. of one year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weighted smoothing\n",
    "\n",
    "In the convolution examples above, we apply the smoothing equally to all samples of the signal.\n",
    "\n",
    "\n",
    "What if we knew that some samples were 'better' (quality) than others? What if some samples were missing? How could we incorporate this information?\n",
    "\n",
    "The answer is to *weight* the convolution.\n",
    "\n",
    "For each sample point in the signal, we define a *weight*, where the weight is high if we trust the data point and low if we don't trust it much. We apply a weight of zero if a data point is missing.\n",
    "\n",
    "Then, the weighted convolution is simply the result of applying the filter to (weight $\\times$ signal), divided by the result of applying the filter to the weight alone. You can think of the denominator here as a form of 're-normalisation' of the filter.\n",
    "\n",
    "We illustrate this by removing samples from the example above, and giving a weight of zero for the 'missing' observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is not as good as we got above, but that is hardly surprising: we are interpolating here and it is hard to interpolate over large gaps.\n",
    "\n",
    "Since the gaps are quite large, we might benefit from using a larger filter extent. This is then liable to degrade the quality somewhat (over smooth) in data rich areas. These are typical trade-offs we must balance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = lai[1]\n",
    "sigma = 8\n",
    "import scipy\n",
    "\n",
    "x = np.arange(-3*sigma,3*sigma+1)\n",
    "gaussian = np.exp((-(x/sigma)**2)/2.0)\n",
    "\n",
    "x = scipy.ndimage.filters.convolve1d(lai[0] * weight, gaussian, axis=0,mode='wrap')\n",
    "w = scipy.ndimage.filters.convolve1d(weight, gaussian, axis=0,mode='wrap')\n",
    "\n",
    "# avoid divide by 0 problems by setting zero values\n",
    "# of the denominator to not a number (NaN)\n",
    "w[w==0] = np.nan\n",
    "\n",
    "# \n",
    "ilai = x/w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## find where the weight is highest, and lets look there!\n",
    "sweight = weight.sum(axis=0)\n",
    "r,c = np.where(sweight == np.max(sweight))\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.title(f'{product} {FIPS} {params[0]} {year} {r[0]},{c[0]}')\n",
    "plt.plot((ilai)[:,r[0],c[0]],'r--')\n",
    "plt.plot((lai[0])[:,r[0],c[0]],'+')\n",
    "plt.ylim(0,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making movies\n",
    "\n",
    "It is often useful to animate time series information. There are several ways of doing this.\n",
    "\n",
    "Bear in mind that the larger the datasets, number of images and/or frames, the more time it is likely to take to generate the animations. You probably don't want more than around 100 frames to make an animation of this sort.\n",
    "\n",
    "The two approaches we will use are:\n",
    "\n",
    "* Javascript HTML in the notebook using `anim.to_jshtml()` from `matplotlib.animation`\n",
    "* Animated gif using the `imageio` library\n",
    "\n",
    "### Javascript HTML\n",
    "\n",
    "This approach uses javascript in html within the notebook to genrate an animation and player. The player is useful, in that we can easily stop at and explore individual frames.\n",
    "\n",
    "The HTML representation is written to a temporary directory (internally to [anim.to_jshtml()](https://matplotlib.org/_modules/matplotlib/animation.html#Animation.to_jshtml)) but deleted on exit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animated gif\n",
    "\n",
    "In the second approach, we save individual frames of an animation, and read them in, using `imageio.imread()` into a list. We choose to write the individual frames here to a temporary directory (so they are cleaned up on exit).\n",
    "\n",
    "This list of `imageio` datasets is then fed to [`imageio.mimsave()`](https://imageio.readthedocs.io/en/stable/userapi.html) to save the sequence as an animated gif. This can then be displayed in a notebook cell (or otherwise). Note that the file [data/MCD15A3H.A2017.h1_78_v0_34_LU.006.gif](data/MCD15A3H.A2017.h1_78_v0_34_LU.006.gif) is saved in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/MCD15A3H.A2017.h1_78_v0_34_LU.006.gif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import imageio\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "'''\n",
    "lai movie as animated gif\n",
    "'''\n",
    "\n",
    "# switch interactive plotting off\n",
    "# as we just want to save trhe frames, \n",
    "# not plot them now\n",
    "plt.ioff()\n",
    "\n",
    "image_folder = Path('images')\n",
    "\n",
    "allopfile = image_folder.\\\n",
    "                joinpath(f'{product}.A{year}.{tile_}.{version:03d}')\n",
    "\n",
    "images = []\n",
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    ofile = f'{tmpdirname}/tmp.png'\n",
    "    \n",
    "    for i in range(ilai.shape[0]):\n",
    "        plt.figure(0,figsize=(10,10))\n",
    "        # don' display the interim frames\n",
    "        plt.ioff()\n",
    "        plt.clf()\n",
    "        plt.imshow(ilai[i],vmin=0,vmax=6,cmap=plt.cm.inferno_r)\n",
    "        plt.title(f'{product} {FIPS} {params[0]} {year} DOY {dt*i+1:03d}')\n",
    "        plt.colorbar(shrink=0.85)\n",
    "        plt.savefig(ofile)    \n",
    "        images.append(imageio.imread(ofile))\n",
    "plt.clf()\n",
    "imageio.mimsave(f'{allopfile}.gif', images)\n",
    "print(f'{allopfile}.gif')\n",
    "# switch interactive plotting back on\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/MCD15A3H.A2017.h1_78_v0_34_LU.006.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "362.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
