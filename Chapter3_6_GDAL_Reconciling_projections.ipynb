{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 Reconciling projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.1 Introduction\n",
    "\n",
    "This section of notes is optional to the course, and the tutor may decide *not* to go through this in class. That said, the information and obexamples contained here can be very useful for accessing and processing certain types of geospatial data.\n",
    "\n",
    "In particular, we deal with obtaining climate data records from [ECMWF](http://apps.ecmwf.int/datasets/data/era40-daily/levtype=sfc) that we will later use for model fitting. These data come in a [netcdf](https://confluence.ecmwf.int/display/CKB/What+are+NetCDF+files+and+how+can+I+read+them) format (commonly used for climate data) with a grid in latitude/longitude. To 'overlay' these data with another dataset (e.g. the MODIS LAI product that we have been using) in a different (equal area) projection, we use the `gdal` function\n",
    "\n",
    "    gdal.ReprojectImage(src, dst, src_proj, dst_proj, interp)\n",
    "       \n",
    "where:\n",
    "\n",
    "    src      : a source dataset that we want to process \n",
    "    dst      : a blank destination dataset that we set up with the \n",
    "               required (output) data type, shape, and geotransform and projection\n",
    "    src_proj : the source dataset projection wkt \n",
    "    dst_proj : the destination projection wkt \n",
    "    interp   : the required interpolation method, e.g. gdalconst.GRA_Bilinear\n",
    "    \n",
    "where wkt stands for [well known text](https://en.wikipedia.org/wiki/Well-known_text) and is a projection format string.\n",
    "\n",
    "Other codes we use are ones we have developed earlier.\n",
    "\n",
    "In these notes, we will learn:\n",
    "\n",
    "    * how to access an ECMWF daily climate dataset (from ERA interim)\n",
    "    * how to reproject the dataset to match another spatial dataset (MODIS LAI)\n",
    "    \n",
    "We will then save some datasets that we will use later in the notes. For this reason, it's possile to skip this section, and return to it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.1.1 Projections\n",
    "\n",
    "For various reasons, different geospatial datasets will come in different [projections](http://desktop.arcgis.com/en/arcmap/10.3/guide-books/map-projections/what-are-map-projections.htm).\n",
    "\n",
    "Considering for example satellite-derived data from Low Earth Orbit (LEO)[https://en.wikipedia.org/wiki/Low_Earth_orbit], the satellite sensor will typically obtain image data in a swath as it passes over the Earth surface. Projected onto the Earth surface, this appears as a strip of data:\n",
    "\n",
    "![https://earthobservatory.nasa.gov/Features/LDCMLongSwath](images/long_swath_map_720.png)\n",
    "\n",
    "but in the satellite data recording system, the data are stored as a regular array. We call such satellite data 'swath' (or 'swath-like') data (in the satellite imager coordinate system) and we may obtain data products in anything up to [Level 2](https://earthdata.nasa.gov/earth-science-data-systems-program/policies/data-information-policy/data-levels) in such a form.\n",
    "\n",
    "These data are often difficult for data scientists to deal with. They generally prefer to have a dataset mapped to a uniform space-time grid, even though this may involve some re-sampling, which can sometimes result in loss of information. The convenience of a uniform space-time grid means that you can. for example, look at dynamic features (information over time).\n",
    "\n",
    "The properties of the 'uniform space-time grid' will depend on [user requirements](http://desktop.arcgis.com/en/arcmap/10.3/tools/coverage-toolbox/choosing-a-map-projection.htm). For some, it is important to have an [equal area projection](https://www.giss.nasa.gov/tools/gprojector/help/projections/), one where the 'pixel size' is consistent throughout the dataset. \n",
    "\n",
    "![https://www.giss.nasa.gov/tools/gprojector/hehttps://www.giss.nasa.gov/tools/gprojector/help/projections/CylindricalEqualArea.png](images/CylindricalEqualArea.png)\n",
    "\n",
    "even if this is not convenient for viewing some areas of the Earth (map projections are very political!).\n",
    "\n",
    "For others, other factors may be more important, such as user familiarity with a simple latitude/longitude grid typically used by climate scientists. \n",
    "\n",
    "![https://www.giss.nasa.gov/tools/gprojector/help/projections/CylindricalStereographic.png](images/CylindricalStereographic.png)\n",
    "\n",
    "For others, a conformal projection (preserving angles, as a cost of distance distortion) may be vital.\n",
    "\n",
    "![https://www.giss.nasa.gov/tools/gprojector/help/projections/AdamsHemisphereInASquare.png](images/AdamsHemisphereInASquare.png)\n",
    "\n",
    "We have see that MODIS data products, for example, come described in an equal area sinusoidal grid:\n",
    "\n",
    "![https://www.giss.nasa.gov/tools/gprojector/help/projections/Sinusoidal.png](images/Sinusoidal.png).\n",
    "\n",
    "but the data for high latitudes and longitudes appears very distorted.\n",
    "\n",
    "We must accept then, that dealing with geospatial data must involve some understanding of projections, as well as practically, how to convert datasets between different projections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.1.2 Changing Projections\n",
    "\n",
    "We can convenienty use the Python [`cartopy`](https://scitools.org.uk/cartopy/docs/v0.16/) package to explore projections.\n",
    "\n",
    "We download an image taken from the satellite sensor ([SEVIRI](https://www.esa.int/Our_Activities/Observing_the_Earth/Meteosat/SEVIRI)):\n",
    "\n",
    "![http://www.esa.int/spaceinimages/Images/2005/12/Artist_s_view_of_SEVIRI_in_orbit](images/Artist_s_view_of_SEVIRI_in_orbit_node_full_image_2.png)\n",
    "\n",
    "The sensor builds up images of the Earth disc from geostationarty orbit, actioned by the platform spin.\n",
    "\n",
    "![http://www.esa.int/spaceinimages/Images/2015/08/MSG-4_Europe_s_latest_weather_satellite_delivers_first_image](images/MSG-4_Europe_s_latest_weather_satellite_delivers_first_image_node_full_image_2.png)\n",
    "\n",
    "In the code below, we plot the dataset in the 'earth disk' (Orthographic) projection, then re-map it to the equal area Sinusoidal projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from urllib2 import urlopen\n",
    "except ImportError:\n",
    "    from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "%matplotlib inline\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "from https://scitools.org.uk/cartopy/docs/v0.16/\\\n",
    "            gallery/geostationary.html#sphx-glr-gallery-geostationary-py\n",
    "'''\n",
    "def geos_image():\n",
    "    \"\"\"\n",
    "    Return a specific SEVIRI image by retrieving it from a github gist URL.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    img : numpy array\n",
    "        The pixels of the image in a numpy array.\n",
    "    img_proj : cartopy CRS\n",
    "        The rectangular coordinate system of the image.\n",
    "    img_extent : tuple of floats\n",
    "        The extent of the image ``(x0, y0, x1, y1)`` referenced in\n",
    "        the ``img_proj`` coordinate system.\n",
    "    origin : str\n",
    "        The origin of the image to be passed through to matplotlib's imshow.\n",
    "\n",
    "    \"\"\"\n",
    "    url = ('https://gist.github.com/pelson/5871263/raw/'\n",
    "           'EIDA50_201211061300_clip2.png')\n",
    "    img_handle = BytesIO(urlopen(url).read())\n",
    "    img = plt.imread(img_handle)\n",
    "    img_proj = ccrs.Geostationary(satellite_height=35786000)\n",
    "    img_extent = [-5500000, 5500000, -5500000, 5500000]\n",
    "    return img, img_proj, img_extent, 'upper'\n",
    "\n",
    "print('Retrieving image...')\n",
    "img, crs, extent, origin = geos_image()\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(1, 1, 1,projection=\\\n",
    "                     ccrs.Orthographic(central_longitude=0.0, central_latitude=0.0))\n",
    "ax.coastlines()\n",
    "ax.set_global()\n",
    "ax.imshow(img, transform=crs, extent=extent, origin=origin, cmap='gray')\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=\\\n",
    "                     ccrs.Sinusoidal(central_longitude=0.0, \\\n",
    "                        false_easting=0.0, false_northing=0.0))\n",
    "ax.coastlines()\n",
    "ax.set_global()\n",
    "print('Projecting and plotting image (this may take a while)...')\n",
    "ax.imshow(img, transform=crs, extent=extent, origin=origin, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full list of [`cartopy` projections](https://scitools.org.uk/cartopy/docs/v0.16/crs/projections.html) is quite entensive.\n",
    "\n",
    "**Exercise 3.6.1** (Homework)\n",
    "\n",
    "* Explore some different types of projection using `cartopy` and make a note of their features.\n",
    "* Read up (follow the links in the text above) on projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do exercise here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.2 Requirements\n",
    "\n",
    "We will need to:\n",
    "\n",
    "* make sure we have the MODIS LAI dataset locally\n",
    "* read them in for a given country.\n",
    "* register with ecmwf, install ecmwfapi\n",
    "* get the temperature datasset from ECMWF for 2006 and 2017 for Europe\n",
    "* get the country borders shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required general imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gdal\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2.1 Run the pre-requisite scripts\n",
    "\n",
    "**Make sure you register with ECMWF**\n",
    "* register with ECMWF and install the API\n",
    "    \n",
    "    Follow the [ECMWF instructions](https://confluence.ecmwf.int/display/WEBAPI/Access+ECMWF+Public+Datasets)\n",
    "\n",
    "**Sort data prerequisities** \n",
    "* Run the codes in the [prerequisites section](Chapter3_6A_GDAL_Reconciling_projections_prerequisites.ipynb)\n",
    "\n",
    "    OR\n",
    "    \n",
    "* Run the [prerequisites script]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install ecmwf api -- do this once only\n",
    "ECMWF = 'https://software.ecmwf.int/wiki/download/attachments/56664858/ecmwf-api-client-python.tgz'\n",
    "try:\n",
    "    from ecmwfapi import ECMWFDataServer\n",
    "except:\n",
    "    import os\n",
    "    if os.name == 'nt':\n",
    "        # on windows\n",
    "        !pip install $ECMWF\n",
    "    else:\n",
    "        # on Unix/Linux\n",
    "        !pip install --user $ECMWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "europe_data_2016_2017.nc exists\n"
     ]
    }
   ],
   "source": [
    "%run geog0111/Chapter3_6A_prerequisites.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the LAI data for given country code\n",
    "country_code = 'UK'\n",
    "year = 2017\n",
    "\n",
    "tiles = []\n",
    "for h in [17, 18]:\n",
    "    for v in [3, 4]:\n",
    "        tiles.append(f\"h{h:02d}v{v:02d}\")\n",
    "        \n",
    "fname = f'lai_data_{year}_{country_code}.npz'\n",
    "ofile = Path('data')/fname\n",
    "try:\n",
    "    # read data from npz file\n",
    "    lai = np.load(ofile)\n",
    "except:\n",
    "    print(f\"{ofile} doesn't exist: sort the pre-requisites\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.3 Reconcile the datasets\n",
    "\n",
    "In this section, we will use `gdal` to transform two datasets into the same coordinate system.\n",
    "\n",
    "To do this, we identify one dataset with the projection and geographic extent that we want for our data (a MODIS sub-dataset here, the 'exemplar').\n",
    "\n",
    "We then download a climate dataset in a latitude/longitude grid ([netcdf](https://www.unidata.ucar.edu/software/netcdf/) format) and transform this to be consistent with the MODIS dataset.\n",
    "\n",
    "\n",
    "### 3.6.3.1 load an exemplar dataset\n",
    "\n",
    "Since we want to match up datasets, we need to produce an example of the dataset we want to match up to.\n",
    "\n",
    "We save the exemplar as a GeoTiff format file here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mosaic_and_clip() got an unexpected keyword argument 'ofolder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7477528c437f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# the t2 dataset to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m match_filename = mosaic_and_clip(tiles,1,2017,ofolder='tmp',\\\n\u001b[0;32m---> 17\u001b[0;31m                     country_code=country_code,shpfile=shpfile,frmat='GTiff')\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: mosaic_and_clip() got an unexpected keyword argument 'ofolder'"
     ]
    }
   ],
   "source": [
    "from osgeo import gdal, gdalconst,osr\n",
    "import numpy as np\n",
    "from geog0111.process_timeseries import mosaic_and_clip\n",
    "\n",
    "country_code = 'UK'\n",
    "shpfile = \"data/TM_WORLD_BORDERS-0.3.shp\"\n",
    "\n",
    "'''\n",
    "https://stackoverflow.com/questions/10454316/\n",
    "how-to-project-and-resample-a-grid-to-match-another-grid-with-gdal-python\n",
    "'''\n",
    "        \n",
    "# first get an exemplar LAI file, clipped to\n",
    "# the required limits. We will use this to match  \n",
    "# the t2 dataset to\n",
    "match_filename = mosaic_and_clip(tiles,1,2017,ofolder='tmp',\\\n",
    "                    country_code=country_code,shpfile=shpfile,frmat='GTiff')\n",
    "\n",
    "print(match_filename)\n",
    "\n",
    "'''\n",
    "Now get the projection, geotransform and dataset\n",
    "size that we want to match to\n",
    "'''\n",
    "match_ds = gdal.Open(match_filename, gdalconst.GA_ReadOnly)\n",
    "match_proj = match_ds.GetProjection()\n",
    "match_geotrans = match_ds.GetGeoTransform()\n",
    "wide = match_ds.RasterXSize\n",
    "high = match_ds.RasterYSize\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(f'Exemplar LAI dataset for {country_code}')\n",
    "plt.imshow(match_ds.ReadAsArray())\n",
    "plt.colorbar(shrink=0.75)\n",
    "# close the file -- we dont need it any more\n",
    "del match_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3.2 get information from source file\n",
    "\n",
    "\n",
    "Now, we pull the information we need from the source file (the netcdf format t2 dataset).\n",
    "\n",
    "We need to know:\n",
    "\n",
    "* the data type\n",
    "* the number of bands (time samples in this case)\n",
    "* the geotransform of the dataset (the fact that it's 0.25 degree resolution over Europe)\n",
    "\n",
    "and access these from the source dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, gdalconst,osr\n",
    "import numpy as np\n",
    "\n",
    "# set up conditions\n",
    "\n",
    "src_filename = 'data/europe_data_2016_2017.nc'\n",
    "\n",
    "'''\n",
    "access information from source\n",
    "'''\n",
    "src_dataname = 'NETCDF:\"'+src_filename+'\":t2m'\n",
    "src_latitude = 'NETCDF:\"'+src_filename+'\":latitude'\n",
    "src_longitude = 'NETCDF:\"'+src_filename+'\":longitude'\n",
    "\n",
    "src     = gdal.Open(src_dataname, gdalconst.GA_ReadOnly)\n",
    "\n",
    "'''\n",
    "Get geotrans, data type and number of bands\n",
    "from source dataset\n",
    "'''\n",
    "band1 = src.GetRasterBand(1)\n",
    "\n",
    "src_geotrans = src.GetGeoTransform()\n",
    "nbands = src.RasterCount\n",
    "src_format = band1.DataType\n",
    "\n",
    "print('Information found')\n",
    "print('GeoTransform:   ',src_geotrans)\n",
    "print('number of bands:',nbands)\n",
    "print('format:         ',src_format)\n",
    "\n",
    "# visualise\n",
    "t2m = band1.ReadAsArray()\n",
    "\n",
    "# get lat/lon from the netcdf file\n",
    "import pdb;pdb.set_trace()\n",
    "src_lat = gdal.Open(src_latitude, gdalconst.GA_ReadOnly)\n",
    "src_lat = src_lat.GetRasterBand(1)\n",
    "src_lon = gdal.Open(src_longitude, gdalconst.GA_ReadOnly)\n",
    "src_lon = src_lon.GetRasterBand(1)\n",
    "lat = src_lat.ReadAsArray()\n",
    "lon = src_lon.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_title(f'T2 ECMWF dataset for {country_code}: band 1')\n",
    "\n",
    "im = plt.contourf(lon, lat, t2m, 256,\\\n",
    "             transform=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "_ = plt.colorbar(im,shrink=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3.3 deal with netcdf projection\n",
    "\n",
    "\n",
    "The netcdf dataset is in a lat/long projection. Usually, we can access this information from:\n",
    "\n",
    "    src.GetProjection()\n",
    "    \n",
    "but this returns a zero-length string from the netcdf file because of the way the corrdinate system data are set.\n",
    "\n",
    "We could develop the mapping using the explicit latitude and longituder information from the netcdf file, as we did im the plot above, but this is not really needed.\n",
    "\n",
    "So, instead we can simply provide information to `gdal.ReprojectImage()` about the projection. The geoid used by the data is [WGS84](https://en.wikipedia.org/wiki/World_Geodetic_System). Information on [`spatialreference.org`](http://spatialreference.org/ref/epsg/wgs-84/) tells us that the appropriate [EPSG](http://spatialreference.org/ref/epsg/) is [4326](http://spatialreference.org/ref/epsg/wgs-84/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, gdalconst,osr\n",
    "\n",
    "# try to get the src projection \n",
    "src_proj = src.GetProjection ()\n",
    "\n",
    "# if (when) we fail, tell it its wgs84\n",
    "if len(src_proj) == 0:\n",
    "    # set up a spatial reference\n",
    "    # as wgs84 \n",
    "    wgs84 = osr.SpatialReference ()\n",
    "    wgs84.ImportFromEPSG ( 4326 )\n",
    "    src_proj = wgs84.ExportToWkt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3.4 reprojection\n",
    "\n",
    "Now, set up a blank gdal dataset (in memory) with the size, data type, projection etc. that we want, the reproject the temperature dataset into this.\n",
    "\n",
    "The processing may take som e time if the LAI dataset is large (e.g. France).\n",
    "\n",
    "The result will be of the same size, projection etc as the cropped LAI dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = gdal.GetDriverByName('MEM').Create('', wide, high, nbands, src_format)\n",
    "\n",
    "dst.SetGeoTransform( match_geotrans )\n",
    "dst.SetProjection( match_proj)\n",
    "\n",
    "print('Information found')\n",
    "print('wide:      ',wide)\n",
    "print('high:      ',high)\n",
    "print('geotrans:  ',match_geotrans)\n",
    "print('projection:',match_proj)\n",
    "\n",
    "# Do the work: reproject the dataset\n",
    "# This will take a few minutes, depending on dataset size\n",
    "_ = gdal.ReprojectImage(src, dst, src_proj, match_proj, gdalconst.GRA_Bilinear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOrigin = match_geotrans[0]\n",
    "yOrigin = match_geotrans[3]\n",
    "pixelWidth = match_geotrans[1]\n",
    "pixelHeight = match_geotrans[5]\n",
    "# the +40 pixels in y is to reconcile gdal and cartoply\n",
    "# it may be related to different ellispoids presumed\n",
    "# It is likely to be different elsewhere but still a y-shift\n",
    "# Its not important as we are using cartoply only to visiualise\n",
    "extent = (xOrigin,xOrigin+pixelWidth*wide,\\\n",
    "         yOrigin+pixelHeight*(high+40),yOrigin+40*pixelHeight)\n",
    "\n",
    "print(extent)\n",
    "\n",
    "'''\n",
    "Visualise\n",
    "'''\n",
    "t2m = dst.GetRasterBand(1).ReadAsArray()\n",
    "match_ds = gdal.Open(match_filename, gdalconst.GA_ReadOnly).ReadAsArray()\n",
    "\n",
    "# visualise\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = plt.subplot ( 1, 2, 1 ,projection=ccrs.Sinusoidal())\n",
    "ax.coastlines('10m')\n",
    "ax.set_title(f'T2m ECMWF dataset for {country_code}: band 1')\n",
    "im = ax.imshow(t2m[::-1],extent=extent)\n",
    "plt.colorbar(im,shrink=0.75)\n",
    "\n",
    "ax = plt.subplot ( 1, 2, 2 ,projection=ccrs.Sinusoidal())\n",
    "ax.coastlines('10m')\n",
    "ax.set_title(f'MODIS LAI {country_code}')\n",
    "im = plt.imshow(match_ds,extent=extent)\n",
    "_ = plt.colorbar(im,shrink=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3.5 crop\n",
    "\n",
    "Finally, we crop the temperature dataset using `gdal.Warp()` and save it to a (GeoTiff) file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Output / destination\n",
    "dst_filename = src_filename.replace('.nc','.tif')\n",
    "# get the no data value: -32767 here\n",
    "frmat = 'GTiff'\n",
    "g = gdal.Warp(dst_filename,\n",
    "            dst,\n",
    "            format=frmat,\n",
    "            dstNodata=-32767,\n",
    "            cutlineDSName=shpfile,\n",
    "            cutlineWhere=f\"FIPS='{country_code:s}'\",\n",
    "            cropToCutline=True)\n",
    "del dst # Flush\n",
    "del g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise\n",
    "t2m = gdal.Open(dst_filename, gdalconst.GA_ReadOnly)\n",
    "t2m = t2m.GetRasterBand(1).ReadAsArray()\n",
    "match_ds = gdal.Open(match_filename, gdalconst.GA_ReadOnly).ReadAsArray()\n",
    "\n",
    "# visualise\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = plt.subplot ( 1, 2, 1 ,projection=ccrs.Sinusoidal())\n",
    "ax.coastlines('10m')\n",
    "ax.set_title(f'T2m ECMWF dataset for {country_code}: band 1')\n",
    "im = ax.imshow(t2m[::-1],extent=extent)\n",
    "plt.colorbar(im,shrink=0.75)\n",
    "\n",
    "ax = plt.subplot ( 1, 2, 2 ,projection=ccrs.Sinusoidal())\n",
    "ax.coastlines('10m')\n",
    "ax.set_title(f'MODIS LAI {country_code}')\n",
    "im = plt.imshow(match_ds,extent=extent)\n",
    "_ = plt.colorbar(im,shrink=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3.6 metadata\n",
    "\n",
    "The netcdf file has metadata that we need to pay attention to.\n",
    "\n",
    "In particular, we need to know \n",
    "\n",
    "* how to scale the data to physical units \n",
    "* how interpret the time units\n",
    "* missing data value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = dict(src.GetMetadata())\n",
    "print(meta.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = float(meta['t2m#add_offset'])\n",
    "scale = float(meta['t2m#scale_factor'])\n",
    "missing = int(meta['t2m#missing_value'])\n",
    "\n",
    "# set missing to nan\n",
    "nodata = (t2 == missing)\n",
    "\n",
    "# convert to C\n",
    "temp2 = t2m * scale + offset - 273.15\n",
    "temp2[nodata] = np.nan\n",
    "\n",
    "# visualise\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = plt.subplot ( 1, 2, 1 ,projection=ccrs.Sinusoidal())\n",
    "ax.coastlines('10m')\n",
    "ax.set_title(f'T2m ECMWF dataset for {country_code}: band 1')\n",
    "im = ax.imshow(temp2[::-1],extent=extent)\n",
    "plt.colorbar(im,shrink=0.75)\n",
    "\n",
    "ax = plt.subplot ( 1, 2, 2 ,projection=ccrs.Sinusoidal())\n",
    "ax.coastlines('10m')\n",
    "ax.set_title(f'MODIS LAI {country_code}')\n",
    "im = plt.imshow(match_ds,extent=extent)\n",
    "_ = plt.colorbar(im,shrink=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta['time#units'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time information is in hours since 1900-01-01 00:00:00.0. This is not such a convenient unit for plotting, so we can use `datetime` to fix that:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = meta['NETCDF_DIM_time_VALUES']\n",
    "print(timer[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the string into integers\n",
    "timer = [int(i) for i in meta['NETCDF_DIM_time_VALUES'][1:-1].split(',')]\n",
    "\n",
    "print (timer[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the string into integers\n",
    "# convert to days\n",
    "timer = [float(i)/24. for i in meta['NETCDF_DIM_time_VALUES'][1:-1].split(',')]\n",
    "\n",
    "print (timer[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "\n",
    "# add base date\n",
    "# split the string into integers\n",
    "# convert to days\n",
    "timer = [(datetime(1900,1,1) + timedelta(days=float(i)/24.)) \\\n",
    "         for i in meta['NETCDF_DIM_time_VALUES'][1:-1].split(',')]\n",
    "\n",
    "print (timer[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.4 Putting this together\n",
    "\n",
    "We can now put these codes together to make a function `match_netcdf_to_data()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, gdalconst,osr\n",
    "import numpy as np\n",
    "from geog0111.process_timeseries import mosaic_and_clip\n",
    "\n",
    "def match_netcdf_to_data(src_filename,match_filename,dst_filename,\\\n",
    "                         country_code=country_code,shpfile=shpfile,\\\n",
    "                         nodata=-32767,frmat='GTiff',verbose=False):\n",
    "\n",
    "    '''\n",
    "    see :\n",
    "    https://stackoverflow.com/questions/10454316/\n",
    "    how-to-project-and-resample-a-grid-to-match-another-grid-with-gdal-python\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Get the projection, geotransform and dataset\n",
    "    size that we want to match to\n",
    "    '''\n",
    "    if verbose: print(f'getting info from match file {match_filename}')\n",
    "    match_ds = gdal.Open(match_filename, gdalconst.GA_ReadOnly)\n",
    "    match_proj = match_ds.GetProjection()\n",
    "    match_geotrans = match_ds.GetGeoTransform()\n",
    "    wide = match_ds.RasterXSize\n",
    "    high = match_ds.RasterYSize\n",
    "    # close the file -- we dont need it any more\n",
    "    del match_ds\n",
    "\n",
    "    '''\n",
    "    access information from source\n",
    "    '''\n",
    "    if verbose: print(f'getting info from source netcdf file {src_filename}')\n",
    "    try:\n",
    "        src_dataname = 'NETCDF:\"'+src_filename+'\":t2m'\n",
    "        src = gdal.Open(src_dataname, gdalconst.GA_ReadOnly)\n",
    "    except:\n",
    "        return(None)\n",
    "    \n",
    "    '''\n",
    "    Get geotrans, data type and number of bands\n",
    "    from source dataset\n",
    "    '''\n",
    "    band1 = src.GetRasterBand(1)\n",
    "    src_geotrans = src.GetGeoTransform()\n",
    "    nbands = src.RasterCount\n",
    "    src_format = band1.DataType\n",
    "    \n",
    "    # try to get the src projection\n",
    "    src_proj = src.GetProjection ()\n",
    "    \n",
    "    # if (when) we fail, tell it its wgs84\n",
    "    if len(src_proj) == 0:\n",
    "        # set up a spatial reference\n",
    "        # as wgs84\n",
    "        wgs84 = osr.SpatialReference ()\n",
    "        wgs84.ImportFromEPSG ( 4326 )\n",
    "        src_proj = wgs84.ExportToWkt()\n",
    "        \n",
    "    if verbose: print(f'setting transform and projection info')\n",
    "    if shpfile:\n",
    "        dst = gdal.GetDriverByName('MEM').Create(\\\n",
    "                                    '', wide, high, \\\n",
    "                                    nbands, src_format)\n",
    "    else:\n",
    "        dst = gdal.GetDriverByName(frmat).Create(\\\n",
    "                                    dst_filename, wide, high, \\\n",
    "                                    nbands, src_format)\n",
    "        \n",
    "    dst.SetGeoTransform( match_geotrans )\n",
    "    dst.SetProjection( match_proj)\n",
    "\n",
    "    # Do the work: reproject the dataset\n",
    "    if verbose: print(f'reprojecting ...')\n",
    "    _ = gdal.ReprojectImage(src, dst, src_proj, match_proj, gdalconst.GRA_Bilinear)\n",
    "\n",
    "    if shpfile:\n",
    "        if verbose: print(f'cropping to {country_code:s}...')\n",
    "        # Output / destination\n",
    "        gdal.Warp(dst_filename,\n",
    "                    dst,\n",
    "                    format=frmat,\n",
    "                    dstNodata=nodata,\n",
    "                    cutlineDSName=shpfile,\n",
    "                    cutlineWhere=f\"FIPS='{country_code:s}'\",\n",
    "                cropToCutline=True)\n",
    "    if verbose: print(f'writing to {dst_filename}')\n",
    "    del dst # Flush\n",
    "    return(dst_filename)\n",
    "\n",
    "\n",
    "def calibrate_t2(t2_filename,meta):\n",
    "    '''\n",
    "    apply scaling etc to temperature data t 2m\n",
    "    '''\n",
    "    # get time info\n",
    "    timer = np.array([(datetime(1900,1,1) + timedelta(days=float(i)/24.)) \\\n",
    "         for i in meta['NETCDF_DIM_time_VALUES'][1:-1].split(',')])\n",
    "\n",
    "    t2 = gdal.Open(dst_filename, gdalconst.GA_ReadOnly)\n",
    "    t2 = np.array([t2.GetRasterBand(i+1).ReadAsArray() \\\n",
    "                   for i in range(timer.shape[0])])\n",
    "    offset = float(meta['t2m#add_offset'])\n",
    "    scale = float(meta['t2m#scale_factor'])\n",
    "    missing = int(meta['t2m#missing_value'])\n",
    "    # set missing to nan\n",
    "    nodata = (t2 == missing)\n",
    "    # convert to C\n",
    "    temp2 = t2 * scale + offset - 273.15\n",
    "    temp2[nodata] = np.nan\n",
    "    return timer,temp2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, gdalconst,osr\n",
    "import numpy as np\n",
    "from geog0111.process_timeseries import mosaic_and_clip\n",
    "from datetime import datetime,timedelta\n",
    "from geog0111.match_netcdf_to_data import match_netcdf_to_data,calibrate_t2\n",
    "\n",
    "'''\n",
    "set force to True to force re-calculation\n",
    "or just load the npz file if it exists\n",
    "'''\n",
    "force = True\n",
    "\n",
    "# set conditions\n",
    "shpfile = \"data/TM_WORLD_BORDERS-0.3.shp\"\n",
    "src_filename = 'data/europe_data_2016_2017.nc'\n",
    "dst_filename = f'data/europe_data_{country_code}_2016_2017.tif'\n",
    "t2_filename = f'data/europe_data_{country_code}_2016_2017.npz'\n",
    "\n",
    "#read LAI\n",
    "fname = f'lai_data_{year}_{country_code}.npz'\n",
    "ofile = Path('data')/fname\n",
    "lai = np.load(ofile)\n",
    "\n",
    "'''\n",
    "bypass the following if its already processed\n",
    "unless we set force = True\n",
    "'''\n",
    "if (force == True) or (not Path(t2_filename).exists):\n",
    "    print(f'calculating dataset match in {t2_filename}')\n",
    "    # first get an exemplar LAI file, clipped to\n",
    "    # the required limits. We will use this to match  \n",
    "    # the t2 dataset to\n",
    "    match_filename = mosaic_and_clip(tiles,1,2017,\\\n",
    "                        country_code=country_code,shpfile=shpfile,frmat='GTiff')\n",
    "    '''\n",
    "    Match the datasets using the function\n",
    "    we have developed\n",
    "    '''\n",
    "    meta = gdal.Open(src_filename, gdalconst.GA_ReadOnly).GetMetadata()\n",
    "\n",
    "    extent = match_netcdf_to_data(src_filename,match_filename,dst_filename,\\\n",
    "                             country_code=country_code,shpfile=shpfile,\\\n",
    "                             nodata=int(meta['t2m#missing_value']),\\\n",
    "                             frmat='GTiff',verbose=False)\n",
    "\n",
    "\n",
    "    # read and interpret the t2 data\n",
    "    timer,temp2 = calibrate_t2(dst_filename,meta)\n",
    "    # save these\n",
    "    np.savez(t2_filename,timer=timer,temp2=temp2,extent=extent)\n",
    "\n",
    "else:\n",
    "    print(f'dataset match in {t2_filename} exists')\n",
    "    t2data = np.load(t2_filename)\n",
    "    timer,temp2,extent = t2data['timer'],t2data['temp2'],t2data['extent']\n",
    "\n",
    "# filter data for required year\n",
    "mask = np.logical_and(timer <= datetime(year,1,1),timer <= datetime(year,12,31))\n",
    "timer = timer[mask]\n",
    "temp2 = temp2[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = plt.subplot ( 2, 2, 1 ,projection=ccrs.Sinusoidal())\n",
    "ax.coastlines('10m')\n",
    "ax.set_title(f'T2m ECMWF dataset for {country_code}: band 1')\n",
    "im = ax.imshow(temp2[0,::-1],extent=extent)\n",
    "plt.colorbar(im,shrink=0.75)\n",
    "\n",
    "ax = plt.subplot ( 2, 2, 2 ,projection=ccrs.Sinusoidal())\n",
    "ax.coastlines('10m')\n",
    "ax.set_title(f'MODIS LAI {country_code}')\n",
    "im = plt.imshow(lai['lai'][:,:,0],vmax=6,extent=extent)\n",
    "_ = plt.colorbar(im,shrink=0.75)\n",
    "\n",
    "plt.subplot ( 2, 2, 3 )\n",
    "plt.plot(timer,np.nanmean(temp2,axis=(1,2)))\n",
    "plt.subplot ( 2, 2, 4 )\n",
    "num = np.nanmean(lai['lai']*lai['weights'],axis=(0,1))\n",
    "den = np.nanmean(lai['weights'],axis=(0,1))\n",
    "plt.plot(num/den)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.5 Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "import matplotlib.pylab as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "'''\n",
    "lai movie javascript/html (jshtml)\n",
    "'''\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(10,10))\n",
    "fig = plt.figure(0,figsize=(10,10))\n",
    "\n",
    "# define an animate function\n",
    "# with the argument i, the frame number\n",
    "def animate(i):\n",
    "    # show frame i of the ilai dataset\n",
    "    plt.figure(0)\n",
    "    im = plt.imshow(interpolated_lai[:,:,i],vmin=0,vmax=6,cmap=plt.cm.inferno_r)\n",
    "    plt.title(f'{product} {FIPS} {params[0]} {year} DOY {4*i+1:03d}')\n",
    "    # make sure to return a tuple!!\n",
    "    return (im,)\n",
    "\n",
    "# set up the animation  \n",
    "anim = animation.FuncAnimation(fig, animate, \n",
    "                               frames=interpolated_lai.shape[2], interval=40, \n",
    "                               blit=True)     \n",
    "\n",
    "# display animation as HTML\n",
    "HTML(anim.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254.1875px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
