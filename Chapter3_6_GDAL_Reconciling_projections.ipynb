{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 Reconciling projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#3.6-Reconciling-projections\" data-toc-modified-id=\"3.6-Reconciling-projections-1\">3.6 Reconciling projections</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.6.1-Introduction\" data-toc-modified-id=\"3.6.1-Introduction-1.1\">3.6.1 Introduction</a></span></li><li><span><a href=\"#3.6.1.1-Projections\" data-toc-modified-id=\"3.6.1.1-Projections-1.2\">3.6.1.1 Projections</a></span></li><li><span><a href=\"#3.6.1.2-Changing-Projections\" data-toc-modified-id=\"3.6.1.2-Changing-Projections-1.3\">3.6.1.2 Changing Projections</a></span></li><li><span><a href=\"#3.6.2-Requirements\" data-toc-modified-id=\"3.6.2-Requirements-1.4\">3.6.2 Requirements</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.6.2.1-Run-the-pre-requisite-scripts\" data-toc-modified-id=\"3.6.2.1-Run-the-pre-requisite-scripts-1.4.1\">3.6.2.1 Run the pre-requisite scripts</a></span></li></ul></li><li><span><a href=\"#3.6.3-Reconcile-the-datasets\" data-toc-modified-id=\"3.6.3-Reconcile-the-datasets-1.5\">3.6.3 Reconcile the datasets</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.6.3.1-load-an-exemplar-dataset\" data-toc-modified-id=\"3.6.3.1-load-an-exemplar-dataset-1.5.1\">3.6.3.1 load an exemplar dataset</a></span></li><li><span><a href=\"#3.6.3.2-get-information-from-source-file\" data-toc-modified-id=\"3.6.3.2-get-information-from-source-file-1.5.2\">3.6.3.2 get information from source file</a></span></li><li><span><a href=\"#3.6.3.4-reprojection\" data-toc-modified-id=\"3.6.3.4-reprojection-1.5.3\">3.6.3.4 reprojection</a></span></li><li><span><a href=\"#3.6.3.5-crop\" data-toc-modified-id=\"3.6.3.5-crop-1.5.4\">3.6.3.5 crop</a></span></li></ul></li><li><span><a href=\"#3.6.3.6-Putting-this-together\" data-toc-modified-id=\"3.6.3.6-Putting-this-together-1.6\">3.6.3.6 Putting this together</a></span></li><li><span><a href=\"#3.6.6-Summary\" data-toc-modified-id=\"3.6.6-Summary-1.7\">3.6.6 Summary</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.1 Introduction\n",
    "\n",
    "This section of notes is optional to the course, and the tutor may decide *not* to go through this in class. \n",
    "\n",
    "That said, the information and examples contained here can be very useful for accessing and processing certain types of geospatial data.\n",
    "\n",
    "In particular, we deal with obtaining climate data records from [ECMWF](http://apps.ecmwf.int/datasets/data/era40-daily/levtype=sfc) that we will later use for model fitting. These data come in a [netcdf](https://confluence.ecmwf.int/display/CKB/What+are+NetCDF+files+and+how+can+I+read+them) format (commonly used for climate data) with a grid in latitude/longitude. To 'overlay' these data with another dataset (e.g. the MODIS LAI product that we have been using) in a different (equal area) projection, we use the `gdal` function\n",
    "\n",
    "    gdal.ReprojectImage(src, dst, src_proj, dst_proj, interp)\n",
    "       \n",
    "where:\n",
    "\n",
    "    src      : a source dataset that we want to process \n",
    "    dst      : a blank destination dataset that we set up with the \n",
    "               required (output) data type, shape, and geotransform and projection\n",
    "    src_proj : the source dataset projection wkt \n",
    "    dst_proj : the destination projection wkt \n",
    "    interp   : the required interpolation method, e.g. gdalconst.GRA_Bilinear\n",
    "    \n",
    "where wkt stands for [well known text](https://en.wikipedia.org/wiki/Well-known_text) and is a projection format string.\n",
    "\n",
    "Other codes we use are ones we have developed earlier.\n",
    "\n",
    "In these notes, we will learn:\n",
    "\n",
    "    * how to access an ECMWF daily climate dataset (from ERA interim)\n",
    "    * how to reproject the dataset to match another spatial dataset (MODIS LAI)\n",
    "    \n",
    "We will then save some datasets that we will use later in the notes. For this reason, it's possile to skip this section, and return to it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.1.1 Projections\n",
    "\n",
    "For various reasons, different geospatial datasets will come in different [projections](http://desktop.arcgis.com/en/arcmap/10.3/guide-books/map-projections/what-are-map-projections.htm).\n",
    "\n",
    "Considering for example, satellite-derived data from Low Earth Orbit [LEO](https://en.wikipedia.org/wiki/Low_Earth_orbit), the satellite sensor will typically obtain image data in a swath as it passes over the Earth surface. Projected onto the Earth surface, this appears as a strip of data:\n",
    "\n",
    "![https://earthobservatory.nasa.gov/Features/LDCMLongSwath](images/long_swath_map_720.png)\n",
    "\n",
    "but in the satellite data recording system, the data are stored as a regular array. We call such satellite data 'swath' (or 'swath-like') data (in the satellite imager coordinate system) and we may obtain data products in anything up to [Level 2](https://earthdata.nasa.gov/earth-science-data-systems-program/policies/data-information-policy/data-levels) in such a form.\n",
    "\n",
    "These data are often difficult for data scientists to deal with. They generally prefer to have a dataset mapped to a uniform space-time grid, even though this may involve some re-sampling, which can sometimes result in loss of information. The convenience of a uniform space-time grid means that you can. for example, look at dynamic features (information over time).\n",
    "\n",
    "The properties of the 'uniform space-time grid' will depend on [user requirements](http://desktop.arcgis.com/en/arcmap/10.3/tools/coverage-toolbox/choosing-a-map-projection.htm). For some, it is important to have an [equal area projection](https://www.giss.nasa.gov/tools/gprojector/help/projections/), one where the 'pixel size' is consistent throughout the dataset. \n",
    "\n",
    "![https://www.giss.nasa.gov/tools/gprojector/hehttps://www.giss.nasa.gov/tools/gprojector/help/projections/CylindricalEqualArea.png](images/CylindricalEqualArea.png)\n",
    "\n",
    "even if this is not convenient for viewing some areas of the Earth (map projections are very political!).\n",
    "\n",
    "Or other factors may be more important, such as user familiarity with a simple latitude/longitude grid typically used by climate scientists. \n",
    "\n",
    "![https://www.giss.nasa.gov/tools/gprojector/help/projections/CylindricalStereographic.png](images/CylindricalStereographic.png)\n",
    "\n",
    "For others, a conformal projection (preserving angles, as a cost of distance distortion) may be vital.\n",
    "\n",
    "![https://www.giss.nasa.gov/tools/gprojector/help/projections/AdamsHemisphereInASquare.png](images/AdamsHemisphereInASquare.png)\n",
    "\n",
    "We have see that MODIS data products, for example, come described in an equal area sinusoidal grid:\n",
    "\n",
    "![https://www.giss.nasa.gov/tools/gprojector/help/projections/Sinusoidal.png](images/Sinusoidal.png).\n",
    "\n",
    "but the data for high latitudes and longitudes appears very distorted.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must accept then, that dealing with geospatial data must involve some understanding of projections, as well as practically, how to convert datasets between different projections.\n",
    "\n",
    "**Earth shape**\n",
    "\n",
    "One factor that can make life even more complicated than using just different projections is the use of different assumptions about the Earth shape (e.g. sphere, spheroid, radius variations). Often, the particular assumptions used by a group of users is just a result of history: it is what has 'traditionally' used for that purpose. It can be seen as too bothersome or expensive to change this.\n",
    "\n",
    "Since we can convert between different projections though, we can also deal with different Earth shape assumptions. We just have to be very clear about what was assumed. If at all possible, the geospatial datasets themselves should contain a full description of the projection and Earth shape assumed, but this is not always the case.\n",
    "\n",
    "The datasets we will mostly be dealing are in the following projections:\n",
    "\n",
    "* MODIS Sinusoidal ([tested](https://github.com/SciTools/cartopy/blob/master/lib/cartopy/tests/crs/test_sinusoidal.py)), which assumes a custom spherical Earth of radius 6371007.181 m. In `cartopy` this is given as [Sinusoidal.MODIS](https://github.com/SciTools/cartopy/blob/master/lib/cartopy/crs.py):\n",
    "   \n",
    "        # MODIS data products use a Sinusoidal projection of a spherical Earth\n",
    "        # http://modis-land.gsfc.nasa.gov/GCTP.html\n",
    "        Sinusoidal.MODIS = Sinusoidal(globe=Globe(ellipse=None,\n",
    "                                              semimajor_axis=6371007.181,\n",
    "                                              semiminor_axis=6371007.181))\n",
    "                                              \n",
    "   In the MODIS data hdf products, the projection information is stored directly. Extracted as a wkt, this is:\n",
    "   \n",
    "       [[PROJCS[\"unnamed\",\n",
    "           GEOGCS[\"Unknown datum based upon the custom spheroid\",\n",
    "               DATUM[\"Not_specified_based_on_custom_spheroid\",\n",
    "                   SPHEROID[\"Custom spheroid\",6371007.181,0]],\n",
    "           PRIMEM[\"Greenwich\",0],\n",
    "           UNIT[\"degree\",0.0174532925199433]],\n",
    "       PROJECTION[\"Sinusoidal\"],\n",
    "       PARAMETER[\"longitude_of_center\",0],\n",
    "       PARAMETER[\"false_easting\",0],\n",
    "       PARAMETER[\"false_northing\",0],\n",
    "       UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]\n",
    "\n",
    "    According to [SR-ORG](http://spatialreference.org/ref/sr-org/6965/), the MODIS projection uses a spherical projection ellipsoid but a WGS84 datum ellipsoid. This is not quite the same as the definition in the wkt above. \n",
    "   \n",
    "    It is also defined by SR-ORG with the EPSG code [6974](http://spatialreference.org/ref/sr-org/6974/) for software that can use `semi_major` and `semi_minor` projection definitions.\n",
    "    \n",
    "    Some software may use the simpler [6965](http://spatialreference.org/ref/sr-org/6965/) definition (or the older [6842](http://spatialreference.org/ref/sr-org/6842/)).\n",
    "    \n",
    "    The MODIS projection 6974 is given as:\n",
    "    \n",
    "        PROJCS[\"MODIS Sinusoidal\",\n",
    "            GEOGCS[\"WGS 84\",\n",
    "                DATUM[\"WGS_1984\",\n",
    "                    SPHEROID[\"WGS 84\",6378137,298.257223563,\n",
    "                        AUTHORITY[\"EPSG\",\"7030\"]],\n",
    "                AUTHORITY[\"EPSG\",\"6326\"]],\n",
    "            PRIMEM[\"Greenwich\",0,\n",
    "                AUTHORITY[\"EPSG\",\"8901\"]],\n",
    "            UNIT[\"degree\",0.01745329251994328,\n",
    "                AUTHORITY[\"EPSG\",\"9122\"]],\n",
    "            AUTHORITY[\"EPSG\",\"4326\"]],\n",
    "        PROJECTION[\"Sinusoidal\"],\n",
    "        PARAMETER[\"false_easting\",0.0],\n",
    "        PARAMETER[\"false_northing\",0.0],\n",
    "        PARAMETER[\"central_meridian\",0.0],\n",
    "        PARAMETER[\"semi_major\",6371007.181],\n",
    "        PARAMETER[\"semi_minor\",6371007.181],\n",
    "        UNIT[\"m\",1.0],\n",
    "        AUTHORITY[\"SR-ORG\",\"6974\"]]\n",
    "        \n",
    "     None of these codes are defined in `gdal` (see files in $GDAL_DATA/*.wkt for details), so to use them, we have to take the file from [SR-ORG](http://spatialreference.org/ref/sr-org/6974/ogcwkt/).\n",
    "     \n",
    "     For the datasets we are using, it makes no real difference whether the projection information from the file is used instead of MODIS projection 6974, so we will use that from the file. For other areas and especially for any higher spatial resolution datasets, it is worth investigating which is more appropriate.\n",
    " \n",
    "* ECMWF netcdf format (derived from GRIB) [ERA Interim](https://www.ecmwf.int/en/forecasts/datasets/archive-datasets/reanalysis-datasets/era-interim) climate datasets (1979-Present). These are geographic coordinates (latitude/longitude) in a custom spheroid with a radius 6371200 m.  \n",
    "\n",
    "This information can be obtained from any example of a GRIB file, as we shall see below. As a wkt, this is:\n",
    "\n",
    "        ['GEOGCS[\"Coordinate System imported from GRIB file\",\n",
    "        DATUM[\"unknown\",SPHEROID[\"Sphere\",6371200,0]],\n",
    "        PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433]]']\n",
    "        \n",
    "* A more common spheroid to use is [WGS84](https://confluence.qps.nl/qinsy/en/world-geodetic-system-1984-wgs84-29855173.html), although even in that case there are multiple 'realisations' available (used mainly by the DoD). Users should generally implement that given in EPSG code [4326](http://spatialreference.org/ref/epsg/4326/) used by the GPS system, for example.\n",
    "\n",
    "        [GEOGCS[\"WGS 84\",\n",
    "            DATUM[\"WGS_1984\",\n",
    "                SPHEROID[\"WGS 84\",6378137,298.257223563,\n",
    "                    AUTHORITY[\"EPSG\",\"7030\"]],\n",
    "                AUTHORITY[\"EPSG\",\"6326\"]],\n",
    "            PRIMEM[\"Greenwich\",0,\n",
    "                AUTHORITY[\"EPSG\",\"8901\"]],\n",
    "            UNIT[\"degree\",0.01745329251994328,\n",
    "                AUTHORITY[\"EPSG\",\"9122\"]],\n",
    "            AUTHORITY[\"EPSG\",\"4326\"]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.1.2 Changing Projections\n",
    "\n",
    "We can conveniently use the Python [`cartopy`](https://scitools.org.uk/cartopy/docs/v0.16/) package to explore projections.\n",
    "\n",
    "We download an image taken from the satellite sensor ([SEVIRI](https://www.esa.int/Our_Activities/Observing_the_Earth/Meteosat/SEVIRI)):\n",
    "\n",
    "![http://www.esa.int/spaceinimages/Images/2005/12/Artist_s_view_of_SEVIRI_in_orbit](images/Artist_s_view_of_SEVIRI_in_orbit_node_full_image_2.png)\n",
    "\n",
    "The sensor builds up images of the Earth disc from geostationarty orbit, actioned by the platform spin.\n",
    "\n",
    "![http://www.esa.int/spaceinimages/Images/2015/08/MSG-4_Europe_s_latest_weather_satellite_delivers_first_image](images/MSG-4_Europe_s_latest_weather_satellite_delivers_first_image_node_full_image_2.png)\n",
    "\n",
    "In the code below, we plot the dataset in the 'earth disk' (Orthographic) projection, then re-map it to the equal area Sinusoidal projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from urllib2 import urlopen\n",
    "except ImportError:\n",
    "    from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "%matplotlib inline\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "are_you_sure = False\n",
    "\n",
    "'''\n",
    "=====================================================\n",
    "Don't run this cell in class as it will take too long!\n",
    "\n",
    "                 Use it for homework\n",
    "                 set are_you_sure = True\n",
    "=====================================================\n",
    "'''\n",
    "\n",
    "'''\n",
    "from https://scitools.org.uk/cartopy/docs/v0.16/\\\n",
    "            gallery/geostationary.html#sphx-glr-gallery-geostationary-py\n",
    "'''\n",
    "def geos_image():\n",
    "    \"\"\"\n",
    "    Return a specific SEVIRI image by retrieving it from a github gist URL.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    img : numpy array\n",
    "        The pixels of the image in a numpy array.\n",
    "    img_proj : cartopy CRS\n",
    "        The rectangular coordinate system of the image.\n",
    "    img_extent : tuple of floats\n",
    "        The extent of the image ``(x0, y0, x1, y1)`` referenced in\n",
    "        the ``img_proj`` coordinate system.\n",
    "    origin : str\n",
    "        The origin of the image to be passed through to matplotlib's imshow.\n",
    "\n",
    "    \"\"\"\n",
    "    url = ('https://gist.github.com/pelson/5871263/raw/'\n",
    "           'EIDA50_201211061300_clip2.png')\n",
    "    img_handle = BytesIO(urlopen(url).read())\n",
    "    img = plt.imread(img_handle)\n",
    "    img_proj = ccrs.Geostationary(satellite_height=35786000)\n",
    "    img_extent = [-5500000, 5500000, -5500000, 5500000]\n",
    "    return img, img_proj, img_extent, 'upper'\n",
    "\n",
    "if are_you_sure:\n",
    "    print('Retrieving image...')\n",
    "    img, crs, extent, origin = geos_image()\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(1, 1, 1,projection=\\\n",
    "                         ccrs.Orthographic(central_longitude=0.0, central_latitude=0.0))\n",
    "    ax.coastlines()\n",
    "    ax.set_global()\n",
    "    ax.imshow(img, transform=crs, extent=extent, origin=origin, cmap='gray')\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=\\\n",
    "                         ccrs.Sinusoidal(central_longitude=0.0, \\\n",
    "                            false_easting=0.0, false_northing=0.0))\n",
    "    ax.coastlines()\n",
    "    ax.set_global()\n",
    "    print('Projecting and plotting image (this may take a while)...')\n",
    "    ax.imshow(img, transform=crs, extent=extent, origin=origin, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full list of [`cartopy` projections](https://scitools.org.uk/cartopy/docs/v0.16/crs/projections.html) is quite entensive.\n",
    "\n",
    "**Exercise 3.6.1** Extra Homework\n",
    "\n",
    "* Explore some different types of projection using `cartopy` and make a note of their features.\n",
    "* Read up (follow the links in the text above) on projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do exercise here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.2 Requirements\n",
    "\n",
    "We will need to:\n",
    "\n",
    "* make sure we have the MODIS LAI dataset locally\n",
    "* read them in for a given country.\n",
    "* register with ecmwf, install ecmwfapi\n",
    "* get the temperature datasset from ECMWF for 2006 and 2017 for Europe\n",
    "* get the country borders shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up the conditions**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required general imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gdal\n",
    "from datetime import datetime, timedelta\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set the country code and year to be used here\n",
    "'''\n",
    "country_code = 'UK'\n",
    "year = 2017\n",
    "shpfile = \"data/TM_WORLD_BORDERS-0.3.shp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2.1 Run the pre-requisite scripts\n",
    "\n",
    "**Make sure you register with ECMWF**\n",
    "* register with ECMWF and install the API\n",
    "    \n",
    "    Follow the [ECMWF instructions](https://confluence.ecmwf.int/display/WEBAPI/Access+ECMWF+Public+Datasets)\n",
    "\n",
    "**Sort data prerequisities** \n",
    "* Run the codes in the [prerequisites section](Chapter3_6A_GDAL_Reconciling_projections_prerequisites.ipynb)\n",
    "\n",
    "    OR\n",
    "    \n",
    "* Run the [prerequisites script]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install ecmwf api -- do this once only\n",
    "ECMWF = 'https://software.ecmwf.int/wiki/download/attachments/56664858/ecmwf-api-client-python.tgz'\n",
    "try:\n",
    "    from ecmwfapi import ECMWFDataServer\n",
    "except:\n",
    "    try:\n",
    "        !pip install $ECMWF\n",
    "    except:\n",
    "        # on Unix/Linux\n",
    "        !pip install --user $ECMWF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just make sure the pre-requisites are run\n",
    "%run geog0111/Chapter3_6A_prerequisites.py $country_code $year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the LAI data for given country code\n",
    "tiles = []\n",
    "for h in [17, 18]:\n",
    "    for v in [3, 4]:\n",
    "        tiles.append(f\"h{h:02d}v{v:02d}\")\n",
    "        \n",
    "fname = f'lai_data_{year}_{country_code}.npz'\n",
    "ofile = Path('data')/fname\n",
    "try:\n",
    "    # read data from npz file\n",
    "    lai = np.load(ofile)\n",
    "    # test that its sensible\n",
    "    lai = np.load(ofile)\n",
    "except:\n",
    "    print(f\"{ofile} doesn't exist: sort the pre-requisites\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick look at some stats to see if there are data there\n",
    "# and they are sensible\n",
    "lai = np.load(ofile)\n",
    "print(np.nanmean(lai['lai'],axis=(0,1)),\\\n",
    "      np.nanmean(lai['weights'],axis=(0,1)))\n",
    "# does it have the interpolated value?\n",
    "if 'interpolated_lai' in list(lai.keys()):\n",
    "    print(np.nanmean(lai['interpolated_lai'],axis=(0,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.3 Reconcile the datasets\n",
    "\n",
    "In this section, we will use `gdal` to transform two datasets into the same coordinate system.\n",
    "\n",
    "To do this, we identify one dataset with the projection and geographic extent that we want for our data (a MODIS sub-dataset here, the 'exemplar').\n",
    "\n",
    "We then download a climate dataset in a latitude/longitude grid ([netcdf](https://www.unidata.ucar.edu/software/netcdf/) format) and transform this to be consistent with the MODIS dataset.\n",
    "\n",
    "\n",
    "### 3.6.3.1 load an exemplar dataset\n",
    "\n",
    "Since we want to match up datasets, we need to produce an example of the dataset we want to match up to.\n",
    "\n",
    "We save the exemplar as a GeoTiff format file here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, gdalconst,osr\n",
    "import numpy as np\n",
    "from geog0111.process_timeseries import mosaic_and_clip\n",
    "\n",
    "# set to True if you want to override\n",
    "# the MODIS projection (see above)\n",
    "use_6974 = False\n",
    "\n",
    "'''\n",
    "https://stackoverflow.com/questions/10454316/\n",
    "how-to-project-and-resample-a-grid-to-match-another-grid-with-gdal-python\n",
    "'''\n",
    "        \n",
    "# first get an exemplar LAI file, clipped to\n",
    "# the required limits. We will use this to match  \n",
    "# the t2 dataset to\n",
    "match_filename = mosaic_and_clip(tiles,1,year,ofolder='tmp',\\\n",
    "                    country_code=country_code,shpfile=shpfile,frmat='GTiff')\n",
    "\n",
    "print(match_filename)\n",
    "\n",
    "'''\n",
    "Now get the projection, geotransform and dataset\n",
    "size that we want to match to\n",
    "'''\n",
    "match_ds = gdal.Open(match_filename, gdalconst.GA_ReadOnly)\n",
    "match_proj = match_ds.GetProjection()\n",
    "match_geotrans = match_ds.GetGeoTransform()\n",
    "wide = match_ds.RasterXSize\n",
    "high = match_ds.RasterYSize\n",
    "\n",
    "print('\\nProjection from file:')\n",
    "print(match_proj,'\\n')\n",
    "\n",
    "'''\n",
    "set Projection 6974 from SR-OR\n",
    "by setting use_6974 = True\n",
    "'''\n",
    "if use_6974:\n",
    "    print('\\nProjection 6974 from SR-ORG:')\n",
    "    modis_wkt = 'data/modis_6974.wkt'\n",
    "    match_proj = open(modis_wkt,'r').readline()\n",
    "    match_ds.SetProjection(match_proj)\n",
    "    print(match_proj,'\\n')\n",
    "\n",
    "'''\n",
    "Visualise\n",
    "'''\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(f'Exemplar LAI dataset for {country_code}')\n",
    "plt.imshow(match_ds.ReadAsArray())\n",
    "plt.colorbar(shrink=0.75)\n",
    "# close the file -- we dont need it any more\n",
    "del match_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3.2 get information from source file\n",
    "\n",
    "\n",
    "Now, we pull the information we need from the source file (the netcdf format t2 dataset).\n",
    "\n",
    "We need to know:\n",
    "\n",
    "* the data type\n",
    "* the number of bands (time samples in this case)\n",
    "* the geotransform of the dataset (the fact that it's 0.25 degree resolution over Europe)\n",
    "\n",
    "and access these from the source dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, gdalconst,osr\n",
    "import numpy as np\n",
    "\n",
    "# set up conditions\n",
    "src_filename = f'data/europe_data_{year}.nc'\n",
    "'''\n",
    "access information from source\n",
    "'''\n",
    "src_dataname = 'NETCDF:\"'+src_filename+'\":t2m'\n",
    "src     = gdal.Open(src_filename, gdalconst.GA_ReadOnly)\n",
    "\n",
    "'''\n",
    "Get geotrans, data type and number of bands\n",
    "from source dataset\n",
    "'''\n",
    "band1 = src.GetRasterBand(1)\n",
    "src_proj = src.GetProjection()\n",
    "src_geotrans = src.GetGeoTransform()\n",
    "nbands = src.RasterCount\n",
    "src_format = band1.DataType\n",
    "nx = band1.XSize\n",
    "ny = band1.YSize\n",
    "\n",
    "print('Information found')\n",
    "print('GeoTransform:   ',src_geotrans)\n",
    "print('Projection:     ',src_proj)\n",
    "print('number of bands:',nbands)\n",
    "print('format:         ',src_format)\n",
    "print('nx,ny:          ',nx,ny)\n",
    "\n",
    "# read data\n",
    "t2m = band1.ReadAsArray()\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot ( 1, 1, 1)\n",
    "ax.set_title(f'T2 ECMWF dataset for {country_code}: band 1')\n",
    "\n",
    "im = plt.imshow(t2m)\n",
    "_ = plt.colorbar(im,shrink=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3.4 reprojection\n",
    "\n",
    "Now, set up a blank gdal dataset (in memory) with the size, data type, projection etc. that we want, the reproject the temperature dataset into this.\n",
    "\n",
    "The processing may take some time if the LAI dataset is large (e.g. France).\n",
    "\n",
    "The result will be of the same size, projection etc as the cropped LAI dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_filename = src_filename.replace('.nc',f'_{country_code}.tif')\n",
    "force = False\n",
    "\n",
    "\n",
    "if (not Path(dst_filename).exists()) or force:\n",
    "    \n",
    "    dst = gdal.GetDriverByName('MEM').Create('', wide, high, nbands, src_format)\n",
    "\n",
    "    dst.SetGeoTransform( match_geotrans )\n",
    "    dst.SetProjection( match_proj)\n",
    "\n",
    "    print('Information found')\n",
    "    print('wide:      ',wide)\n",
    "    print('high:      ',high)\n",
    "    print('geotrans:  ',match_geotrans)\n",
    "    print('projection:',match_proj)\n",
    "\n",
    "    # Do the work: reproject the dataset\n",
    "    # This will take a few minutes, depending on dataset size\n",
    "    _ = gdal.ReprojectImage(src, dst, src_proj, match_proj, gdalconst.GRA_Bilinear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xOrigin = match_geotrans[0]\n",
    "yOrigin = match_geotrans[3]\n",
    "pixelWidth = match_geotrans[1]\n",
    "pixelHeight = match_geotrans[5]\n",
    "\n",
    "extent = (xOrigin,xOrigin+pixelWidth*wide,\\\n",
    "         yOrigin+pixelHeight*(high),yOrigin+pixelHeight)\n",
    "\n",
    "print(extent)\n",
    "    \n",
    "if (not Path(dst_filename).exists()) or force:\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    Visualise: takes some time to plot\n",
    "               due to reprojections\n",
    "    '''\n",
    "    t2m = dst.GetRasterBand(1).ReadAsArray()\n",
    "    match_ds = gdal.Open(match_filename, gdalconst.GA_ReadOnly).ReadAsArray()\n",
    "\n",
    "    # visualise\n",
    "    plt.figure(figsize=(15,10))\n",
    "    ax = plt.subplot ( 1, 2, 1 ,projection=ccrs.Sinusoidal.MODIS)\n",
    "    ax.coastlines('10m')\n",
    "    ax.set_title(f'T2m ECMWF dataset for {country_code}: band 1')\n",
    "    im = ax.imshow(t2m[::-1],extent=extent)\n",
    "    plt.colorbar(im,shrink=0.75)\n",
    "\n",
    "\n",
    "    ax = plt.subplot ( 1, 2, 2 ,projection=ccrs.Sinusoidal.MODIS)\n",
    "    ax.coastlines('10m')\n",
    "    ax.set_title(f'MODIS LAI {country_code}')\n",
    "    im = plt.imshow(match_ds,extent=extent)\n",
    "    _ = plt.colorbar(im,shrink=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3.5 crop\n",
    "\n",
    "Finally, we crop the temperature dataset using `gdal.Warp()` and save it to a (GeoTiff) file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Output / destination\n",
    "dst_filename = src_filename.replace('.nc',f'_{country_code}.tif')\n",
    "force = False\n",
    "\n",
    "\n",
    "if (not Path(dst_filename).exists()) or force:\n",
    "    '''\n",
    "    Only run this if file doesnt exist\n",
    "    '''\n",
    "    frmat = 'GTiff'\n",
    "    g = gdal.Warp(dst_filename,\n",
    "                dst,\n",
    "                format=frmat,\n",
    "                dstNodata=-300,\n",
    "                cutlineDSName=shpfile,\n",
    "                cutlineWhere=f\"FIPS='{country_code:s}'\",\n",
    "                cropToCutline=True)\n",
    "    del dst # Flush\n",
    "    del g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise\n",
    "print(dst_filename)\n",
    "t2m = gdal.Open(dst_filename, gdalconst.GA_ReadOnly)\n",
    "t2m = t2m.GetRasterBand(1).ReadAsArray()\n",
    "t2m[t2m==-300] = np.nan\n",
    "match_ds = gdal.Open(match_filename, gdalconst.GA_ReadOnly).ReadAsArray()\n",
    "\n",
    "# visualise\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = plt.subplot ( 1, 2, 1 ,projection=ccrs.Sinusoidal.MODIS)\n",
    "ax.coastlines('10m')\n",
    "ax.set_title(f'T2m ECMWF dataset for {country_code}: band 1')\n",
    "im = ax.imshow(t2m[::-1],extent=extent)\n",
    "plt.colorbar(im,shrink=0.75)\n",
    "\n",
    "ax = plt.subplot ( 1, 2, 2 ,projection=ccrs.Sinusoidal.MODIS)\n",
    "ax.coastlines('10m')\n",
    "ax.set_title(f'MODIS Exemplar LAI {country_code}')\n",
    "im = plt.imshow(match_ds,extent=extent)\n",
    "_ = plt.colorbar(im,shrink=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the time information in the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = gdal.Open(src_filename).GetMetadata()\n",
    "\n",
    "print(meta['time#units'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time information is in hours since `1900-01-01 00:00:00.0`. This is not such a convenient unit for plotting, so we can use `datetime` to fix that:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = meta['NETCDF_DIM_time_VALUES']\n",
    "print(timer[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the string into integers\n",
    "timer = [int(i) for i in meta['NETCDF_DIM_time_VALUES'][1:-1].split(',')]\n",
    "\n",
    "print (timer[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the string into integers\n",
    "# convert to days\n",
    "timer = [float(i)/24. for i in meta['NETCDF_DIM_time_VALUES'][1:-1].split(',')]\n",
    "\n",
    "print (timer[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "\n",
    "# add base date\n",
    "# split the string into integers\n",
    "# convert to days\n",
    "timer = [(datetime(1900,1,1) + timedelta(days=float(i)/24.)) \\\n",
    "         for i in meta['NETCDF_DIM_time_VALUES'][1:-1].split(',')]\n",
    "\n",
    "print (timer[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.3.6 Putting this together\n",
    "\n",
    "We can now put these codes together to make a function `match_netcdf_to_data()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, gdalconst,osr\n",
    "import numpy as np\n",
    "from geog0111.process_timeseries import mosaic_and_clip\n",
    "from datetime import datetime \n",
    "\n",
    "def match_netcdf_to_data(src_filename,match_filename,dst_filename,year,\\\n",
    "                         country_code=None,shpfile=None,force=False,\\\n",
    "                         nodata=-300,frmat='GTiff',verbose=False):\n",
    "\n",
    "    '''\n",
    "    see :\n",
    "    https://stackoverflow.com/questions/10454316/\n",
    "    how-to-project-and-resample-a-grid-to-match-another-grid-with-gdal-python\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Get the projection, geotransform and dataset\n",
    "    size that we want to match to\n",
    "    '''\n",
    "    if verbose: print(f'getting info from match file {match_filename}')\n",
    "    match_ds = gdal.Open(match_filename, gdalconst.GA_ReadOnly)\n",
    "\n",
    "    match_proj = match_ds.GetProjection()\n",
    "    match_geotrans = match_ds.GetGeoTransform()\n",
    "    wide = match_ds.RasterXSize\n",
    "    high = match_ds.RasterYSize\n",
    "    # close the file -- we dont need it any more\n",
    "    del match_ds\n",
    "\n",
    "    '''\n",
    "    access information from source\n",
    "    '''\n",
    "    if verbose: print(f'getting info from source netcdf file {src_filename}')\n",
    "    try:\n",
    "        src_dataname = 'NETCDF:\"'+src_filename+'\":t2m'\n",
    "        src = gdal.Open(src_dataname, gdalconst.GA_ReadOnly)\n",
    "    except:\n",
    "        if verbose: print('failed')\n",
    "        return(None)\n",
    "\n",
    "    # get meta data\n",
    "    meta = gdal.Open(src_filename, gdalconst.GA_ReadOnly).GetMetadata()\n",
    "\n",
    "    extent = [match_geotrans[0],match_geotrans[0]+match_geotrans[1]*wide,\\\n",
    "              match_geotrans[3]+match_geotrans[5]*high,match_geotrans[3]]\n",
    "    # get time info\n",
    "    timer = np.array([(datetime(1900,1,1) + timedelta(days=float(i)/24.)) \\\n",
    "         for i in meta['NETCDF_DIM_time_VALUES'][1:-1].split(',')])\n",
    "\n",
    "    if (not Path(dst_filename).exists()) or force:\n",
    "\n",
    "        '''\n",
    "        Get geotrans, proj, data type and number of bands\n",
    "        from source dataset\n",
    "        '''\n",
    "        band1 = src.GetRasterBand(1)\n",
    "        src_geotrans = src.GetGeoTransform()\n",
    "        src_proj = src.GetProjection()\n",
    "\n",
    "        nbands = src.RasterCount\n",
    "        src_format = band1.DataType\n",
    "\n",
    "        dst = gdal.GetDriverByName('MEM').Create(\\\n",
    "                                        '', wide, high, \\\n",
    "                                        nbands, src_format)\n",
    "        dst.SetGeoTransform( match_geotrans )\n",
    "        dst.SetProjection( match_proj)\n",
    "\n",
    "        if verbose: print(f'reprojecting ...')\n",
    "            # Output / destination\n",
    "        _ = gdal.ReprojectImage(src, dst, \\\n",
    "                                    src_proj, \\\n",
    "                                    match_proj,\\\n",
    "                                    gdalconst.GRA_Bilinear )\n",
    "        if verbose: print(f'cropping to {country_code:s} ...')\n",
    "        done = gdal.Warp(dst_filename,\n",
    "                        dst,\n",
    "                        format=frmat,\n",
    "                        dstNodata=nodata,\n",
    "                        cutlineDSName=shpfile,\n",
    "                        cutlineWhere=f\"FIPS='{country_code:s}'\",\n",
    "                        cropToCutline=True)\n",
    "        del dst\n",
    " \n",
    "    return(timer,dst_filename,extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, gdalconst,osr\n",
    "import numpy as np\n",
    "from geog0111.process_timeseries import mosaic_and_clip\n",
    "from datetime import datetime,timedelta\n",
    "from geog0111.match_netcdf_to_data import match_netcdf_to_data\n",
    "from geog0111.geog_data import procure_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "# set conditions\n",
    "\n",
    "country_code = 'UK'\n",
    "year = 2017\n",
    "shpfile = \"data/TM_WORLD_BORDERS-0.3.shp\"\n",
    "src_filename = f'data/europe_data_{year}.nc'\n",
    "dst_filename = f'data/europe_data_{year}_{country_code}.tif'\n",
    "t2_filename = f'data/europe_data_{year}_{country_code}.npz'\n",
    "# read in the LAI data for given country code\n",
    "tiles = []\n",
    "for h in [17, 18]:\n",
    "    for v in [3, 4]:\n",
    "        tiles.append(f\"h{h:02d}v{v:02d}\")\n",
    "        \n",
    "\n",
    "#read LAI\n",
    "fname = f'lai_data_{year}_{country_code}.npz'\n",
    "ofile = Path('data')/fname\n",
    "lai = np.load(ofile)\n",
    "\n",
    "if not Path(t2_filename).exists():\n",
    "    print(f'calculating dataset match in {t2_filename}')\n",
    "    # first get an exemplar LAI file, clipped to\n",
    "    # the required limits. We will use this to match  \n",
    "    # the t2 dataset to\n",
    "    match_filename = mosaic_and_clip(tiles,1,year,\\\n",
    "                        country_code=country_code,\\\n",
    "                        shpfile=shpfile,frmat='GTiff')\n",
    "    '''\n",
    "    Match the datasets using the function\n",
    "    we have developed\n",
    "    '''\n",
    "    meta = gdal.Open(src_filename, gdalconst.GA_ReadOnly).GetMetadata()\n",
    "\n",
    "    timer,dst_filename,extent = match_netcdf_to_data(\\\n",
    "                                    src_filename,match_filename,\\\n",
    "                                    dst_filename,year,\\\n",
    "                                    country_code=country_code,\\\n",
    "                                    shpfile=shpfile,\\\n",
    "                                    nodata=-300,frmat='GTiff',\\\n",
    "                                    verbose=True)\n",
    "\n",
    "    # read and interpret the t2 data and flip\n",
    "    temp2 = gdal.Open(dst_filename).ReadAsArray()[:,::-1]\n",
    "    temp2[temp2==-300] = np.nan\n",
    "    temp2 -= 273.15\n",
    "    # save these\n",
    "    print(f'saving data to {t2_filename}')\n",
    "    np.savez_compressed(t2_filename,timer=timer,temp2=temp2,extent=extent)\n",
    "\n",
    "else:\n",
    "    print(f'dataset in {t2_filename} exists')\n",
    "    \n",
    "print('done')\n",
    "t2data = np.load(t2_filename)\n",
    "timer,temp2,extent = t2data['timer'],t2data['temp2'],t2data['extent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the interpolated dataset\n",
    "import matplotlib.pylab as plt\n",
    "import cartopy.crs as ccrs\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "ax = plt.subplot ( 2, 2, 1 ,projection=ccrs.Sinusoidal.MODIS)\n",
    "ax.coastlines('10m')\n",
    "ax.set_title(f'T2m ECMWF dataset for {country_code}: {str(timer[0])}')\n",
    "im = ax.imshow(temp2[0],extent=extent)\n",
    "plt.colorbar(im,shrink=0.75)\n",
    "\n",
    "ax = plt.subplot ( 2, 2, 2 ,projection=ccrs.Sinusoidal.MODIS)\n",
    "ax.coastlines('10m')\n",
    "ax.set_title(f'MODIS LAI {country_code}: {str(timer[0])}')\n",
    "im = plt.imshow(interpolated_lai[:,:,0],vmax=6,extent=extent)\n",
    "_ = plt.colorbar(im,shrink=0.75)\n",
    "\n",
    "plt.subplot ( 2, 2, 3 )\n",
    "plt.title(f'mean T2m for {country_code}')\n",
    "plt.plot(timer,np.nanmean(temp2,axis=(1,2)))\n",
    "plt.ylabel('temperature 2m / C')\n",
    "plt.subplot ( 2, 2, 4 )\n",
    "plt.title(f'mean LAI for {country_code}')\n",
    "mean = np.nanmean(interpolated_lai,axis=(0,1))\n",
    "plt.plot(timer[::4],mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.6 Summary\n",
    " \n",
    "In this section, we have learned about projections, and have reconciled two datasets that were originally in different projections. NThey also were defined with geoids with different Earth radius assumptions.\n",
    "\n",
    "These issues are typical when dealing with geospatial data. \n",
    "\n",
    "This part of the notes is non compulsory, as the codes and ideas are quite complicated for people just begining to learn coding. We have included it here to allow students to revisit this later. It is also included because we want to develop some interesting datasets for modelling, so we need to deal with reconciling datasets from different providers in different projections.\n",
    "\n",
    "In this section, we have developed the following datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geog0111.geog_data import procure_dataset\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "year = 2017\n",
    "country_code = 'UK'\n",
    "'''\n",
    "LAI data\n",
    "'''\n",
    "# read in the LAI data for given country code\n",
    "lai_filename = f'data/lai_data_{year}_{country_code}.npz'\n",
    "# get the dataset in case its not here\n",
    "procure_dataset(Path(lai_filename).name,verbose=False)\n",
    "\n",
    "lai = np.load(lai_filename)\n",
    "print(lai_filename,list(lai.keys()))\n",
    "\n",
    "'''\n",
    "T 2m data\n",
    "'''\n",
    "t2_filename = f'data/europe_data_{year}_{country_code}.npz'\n",
    "# get the dataset in case its not here\n",
    "procure_dataset(Path(t2_filename).name,verbose=False)\n",
    "t2data = np.load(t2_filename)\n",
    "print(t2_filename,list(t2data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick look at some stats to see if there are data there\n",
    "# and they are sensible\n",
    "lai = np.load(ofile)\n",
    "print(np.nanmean(lai['lai'],axis=(0,1)),\\\n",
    "      np.nanmean(lai['weights'],axis=(0,1)))\n",
    "# does it have the interpolated value?\n",
    "if 'interpolated_lai' in list(lai.keys()):\n",
    "    print(np.nanmean(lai['interpolated_lai'],axis=(0,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.6.2** Extra Homework\n",
    "\n",
    "Go carefully through these notes and make notes of the processes we have to go through to reconcile datasets such as these.\n",
    "\n",
    "Learn what issues to look out for when coming across a new dataset, and how to use Python code to deal with it. Try to stick to one geospatial package as far as possible (`gdal` here) as you can make problems for yourself by mixing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do exercise here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254.1875px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
