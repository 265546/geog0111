{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Stacking and interpolating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[up to 3.0](Chapter3_1_GDAL.ipynb)]\n",
    "\n",
    "\n",
    "## 3.4.1 Introduction\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "* develop code to produce a stacked dataset of spatio-temporal data on a grid\n",
    "* interpolate over any missing data\n",
    "* smooth the dataset\n",
    "\n",
    "### 3.4.1.1 Test your login\n",
    "\n",
    "Let's first test your NASA login:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geog0111.nasa_requests as nasa_requests\n",
    "from geog0111.cylog import cylog\n",
    "%matplotlib inline\n",
    "\n",
    "url = 'https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2018.09.30/' \n",
    "        \n",
    "# grab the HTML information\n",
    "try:\n",
    "    html = nasa_requests.get(url).text\n",
    "    # test a few lines of the html\n",
    "    if html[:20] == '<!DOCTYPE HTML PUBLI':\n",
    "        print('this seems to be ok ... ')\n",
    "        print('use cylog().login() anywhere you need to specify the tuple (username,password)')\n",
    "except:\n",
    "    print('login error ... try entering your username password again')\n",
    "    print('then re-run this cell until it works')\n",
    "    cylog(init=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1.2 Get the datasets for today\n",
    "\n",
    "Now let's get the datasets we need for today.\n",
    "\n",
    "**You should run this section before the class starts to save time.**\n",
    "\n",
    "You are given the relevant filenamnes (for 2016 and 2017) in the files [`data/lai_filelist_{year}.dat.txt`](data/lai_filelist_2016.dat.txt). The datasets have been pre-downloaded for this exercise, but you need to copy then to the local filespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from geog0111.geog_data import *\n",
    "\n",
    "destination_folder = 'data'\n",
    "\n",
    "# we have the filenames provided \n",
    "# in data/lai_filelist_2016.dat.txt\n",
    "for year in [2016,2017]:\n",
    "    control_file = f'data/lai_filelist_{year}.dat.txt'\n",
    "    # read the file in\n",
    "    filenames = open(control_file).read().split()\n",
    "\n",
    "    # get the local files\n",
    "    # set verbose=True if you want to see what is happening\n",
    "    # in procure_dataset()\n",
    "    done = [procure_dataset(f,\\\n",
    "                verbose=False,\\\n",
    "                destination_folder=destination_folder) \n",
    "                                    for f in filenames]\n",
    "    # done should be all True if this has worked\n",
    "    # its length should be the number of files copied\n",
    "\n",
    "    # get the dataset names\n",
    "    gdal_fnames = [f'HDF4_EOS:EOS_GRID:\"{destination_folder}/{file_name:s}\":MOD_Grid_MCD15A3H:Lai_500m'\n",
    "                   for file_name in filenames]\n",
    "\n",
    "    # print the first 8 juist to see it looks ok\n",
    "    for f in gdal_fnames[:8]:\n",
    "        print (f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.1 A time series\n",
    "\n",
    "You should now know how to access and download datasets from the NASA servers and have developed functions to do this.\n",
    "\n",
    "You should also know how to select a dataset from a set of hdf files, and mosaic, mask and crop the data to correspond to some vector boundary. This is a very common task in geospatial processing.\n",
    "\n",
    "We now consider the case where we want to analyse a time series of data. We will use LAI over time to exemplify this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#def process_data(doy_year,tiles,vector_file, vector_where):\n",
    "    \n",
    "    \n",
    "def mosaic_and_mask_data(gdal_fnames, vector_file, vector_where):\n",
    "    stitch_vrt = gdal.BuildVRT(\"\", gdal_fnames)\n",
    "    g = gdal.Warp(\"\", stitch_vrt,\n",
    "                 format = 'MEM', dstNodata=200,\n",
    "                  cutlineDSName = vector_file,\n",
    "                  cutlineWhere = vector_where)\n",
    "    return g\n",
    "\n",
    "\n",
    "# this part is to access a particular dataset in the file\n",
    "gdal_fnames = [f'HDF4_EOS:EOS_GRID:\"{file_name:s}\":MOD_Grid_MCD15A3H:Lai_500m'\n",
    "               for file_name in filenames]\n",
    "\n",
    "g = mosaic_and_mask_data(gdal_fnames, \"data/TM_WORLD_BORDERS-0.3.shp\",\n",
    "                         \"FIPS='GM'\")\n",
    "\n",
    "lai = np.array(g.ReadAsArray()).astype(float) * 0.1 # for LAI scaling\n",
    "# valid data mask\n",
    "mask = np.nonzero(lai < 20)\n",
    "min_y = mask[0].min()\n",
    "max_y = mask[0].max() + 1\n",
    "\n",
    "min_x = mask[1].min()\n",
    "max_x = mask[1].max() + 1\n",
    "\n",
    "lai = lai[min_y:max_y,\n",
    "               min_x:max_x]\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "im = plt.imshow(lai, interpolation=\"nearest\", vmin=0, vmax=6,\n",
    "             cmap=plt.cm.inferno_r)\n",
    "plt.title('LAI'+' '+str(tiles)+' '+str((doy,year)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "362.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
